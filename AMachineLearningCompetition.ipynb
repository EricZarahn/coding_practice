{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This notebook has Python code I wrote for an Avito kaggle competition. I have placed it in this repository\n",
    "simply to illustrate my ability to use tensorflow, keras, and pandas. The neural network, which utilized \n",
    "multiple LSTMs, is defined in this notebook in a function called define_model(). This notebook does not display \n",
    "any meaningful results for that competition as it is simply here to show my code.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericz\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model,load_model\n",
    "from keras import layers as L\n",
    "from keras import optimizers as K_opt\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgbm\n",
    "import GPyOpt\n",
    "#from text_sequencing import *\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from translate import Translator\n",
    "from pymystem3 import Mystem\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),'neural-image-assessment-master'))\n",
    "from path import Path\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input,decode_predictions\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input as VGG19_preprocess_input,decode_predictions as VGG19_decode_predictions\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from utils.score_utils import mean_score, std_score\n",
    "\n",
    "#    num_classification_units = object_classification_model.layers[-1].units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "global variables\n",
    "\"\"\"\n",
    "ENGLISH_LETTERS = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P',\\\n",
    "                  'Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "\n",
    "ENGLISH_LETTERS += list(map(lambda x: x.lower(),ENGLISH_LETTERS))\n",
    "\n",
    "NUMERALS = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "DECIMAL_REPLACEMENT_CHAR = '^'\n",
    "\n",
    "#leaving out hyphen\n",
    "PUNCTUATION_MARKS = '!\"#$%&()*+,./:;<=>?^@[\\]_`{|}~'\n",
    "    \n",
    "PUNCTUATION_MARKS = \\\n",
    "[p for p in PUNCTUATION_MARKS if p != DECIMAL_REPLACEMENT_CHAR]\n",
    "\n",
    "#maximum lengths in tokens\n",
    "DESCRIPTION_MAX_LEN = 50\n",
    "TITLE_MAX_LEN = 10\n",
    "\n",
    "AVITO_DATA_DIR = r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data' \n",
    "\n",
    "OBJECT_CLASSIFICATION_SAVE_DIR = \\\n",
    "os.path.join(os.path.dirname(os.getcwd()),r'data\\object_classifications')\n",
    "\n",
    "NUM_OBJECT_CLASSES = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_active_CSV(csv_path,nrows = None,skiprows = None):\n",
    "    \n",
    "    return pd.read_csv(csv_path,parse_dates = ['activation_date'],\\\n",
    "    date_parser = lambda x: pd.to_datetime(x,format = \"%Y-%m-%d\"),\\\n",
    "    nrows = nrows,skiprows = skiprows)\n",
    "\n",
    "    \n",
    "def load_main_CSV(csv_path,nrows = None):\n",
    "    \n",
    "    print('loading {:s}...'.format(csv_path))\n",
    "    \n",
    "    if (nrows is None):\n",
    "    \n",
    "        return pd.read_csv(csv_path,parse_dates = ['activation_date'],\\\n",
    "        date_parser = lambda x: pd.to_datetime(x,format = \"%Y-%m-%d\"),\\\n",
    "        dtype = {'item_id': str, 'user_id': str, 'region': str,\\\n",
    "        'city': str, 'parent_category_name': str, 'category_name': str,\\\n",
    "        'param_1': str, 'param_2': str, 'param_3': str,\\\n",
    "        'title': str,'description': str, 'price': np.float32, \\\n",
    "        'item_seq_number': np.int32,\\\n",
    "        'user_type': str, 'image': str, 'image_top_1': np.float32, \\\n",
    "        'deal_probability': np.float32})\n",
    "        \n",
    "    else:\n",
    "\n",
    "        return pd.read_csv(csv_path,parse_dates = ['activation_date'],\\\n",
    "        date_parser = lambda x: pd.to_datetime(x,format = \"%Y-%m-%d\"),\\\n",
    "        nrows = nrows,\\\n",
    "        dtype = {'item_id': str, 'user_id': str, 'region': str,\\\n",
    "        'city': str, 'parent_category_name': str, 'category_name': str,\\\n",
    "        'param_1': str, 'param_2': str, 'param_3': str,\\\n",
    "        'title': str,'description': str, 'price': np.float32, \\\n",
    "        'item_seq_number': np.int32,\\\n",
    "        'user_type': str, 'image': str, 'image_top_1': np.float32, \\\n",
    "        'deal_probability': np.float32})\n",
    "    \n",
    "    \n",
    "def start_up(load_CSV_only_flag = False,\\\n",
    "    word_to_glove_vec = None,embedding_layers_dict = None):\n",
    "    \"\"\"\n",
    "    Performs steps required prior to training any models.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #load processed competition CSV\n",
    "    net_CSV_path = os.path.join(AVITO_DATA_DIR,'processed_net.csv')\n",
    "\n",
    "    net_CSV = load_main_CSV(net_CSV_path)\n",
    "\n",
    "    print(\"loaded net_CSV\")\n",
    "\n",
    "    if (load_CSV_only_flag):\n",
    "\n",
    "        return net_CSV\n",
    "        \n",
    "    #create logical arrays representing training and validation records of competition train CSV\n",
    "    tr_val_log_dict = return_training_and_validation_logical_dict(net_CSV)\n",
    "    \n",
    "    print(\"# training records = {:d}\".format(tr_val_log_dict['training_logical'].sum()))\n",
    "    print(\"# validation records = {:d}\".format(tr_val_log_dict['validation_logical'].sum()))\n",
    "    print(\"# test records = {:d}\".format(tr_val_log_dict['test_logical'].sum()))\n",
    "    print(\"total # records in net_CSV = {:d}\".format(net_CSV.shape[0]))\n",
    "    print(\"% of total train CSV records comprising validation = {:.1f}\".format(\\\n",
    "    100*tr_val_log_dict['validation_logical'].sum()/(\\\n",
    "    tr_val_log_dict['training_logical'].sum() + tr_val_log_dict['validation_logical'].sum())))\n",
    "    \n",
    "    #load pre-trained word-to-glove vector dict\n",
    "    if (word_to_glove_vec is None):\n",
    "        word_to_glove_vec = return_word2glovevec_dict(\\\n",
    "        glove_filename = \\\n",
    "        r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\ft_native_300_ru_wiki_lenta_nltk_wordpunct_tokenize-002.vec\")\n",
    "    \n",
    "    #create dictionary with tokenizers for LSTMs\n",
    "    LSTM_tokenizer_dict = {}\n",
    "\n",
    "    columns_to_tokenize = ['description_processed','title_processed']\n",
    "    \n",
    "    for column_to_tokenize in columns_to_tokenize:\n",
    "\n",
    "        if False:\n",
    "\n",
    "            #train a tokenizer on 'description_processed' field using training records from train_CSV\n",
    "            #(does not need to be redone if tokenizer was previously saved to file)\n",
    "            tokenizer = tokenizer_for_LSTM(net_CSV,column_to_tokenize,tr_val_log_dict)\n",
    "\n",
    "        else:\n",
    "\n",
    "            tokenizer_file_name = \\\n",
    "            os.path.join(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data',column_to_tokenize + '_tokenizer.pkl')\n",
    "\n",
    "            if False:\n",
    "                with open(tokenizer_file_name,mode = 'wb') as tokenizer_fobj:\n",
    "                    pickle.dump(tokenizer, tokenizer_fobj)\n",
    "                    del tokenizer\n",
    "            else:\n",
    "                with open(tokenizer_file_name,mode = 'rb') as tokenizer_fobj:\n",
    "                    tokenizer = pickle.load(tokenizer_fobj)\n",
    "\n",
    "                    LSTM_tokenizer_dict[column_to_tokenize] = tokenizer\n",
    "                    \n",
    "    if (embedding_layers_dict is None):                \n",
    "        #create keras embedding layers using pre-trained word vectors\n",
    "        embedding_layers_dict = {}\n",
    "\n",
    "        embedding_layers_dict['description_processed'] = pretrained_embedding_layer(\\\n",
    "        word_to_vec_map = word_to_glove_vec, tokenizer = LSTM_tokenizer_dict['description_processed'])\n",
    "\n",
    "        embedding_layers_dict['title_processed'] = pretrained_embedding_layer(\\\n",
    "        word_to_vec_map = word_to_glove_vec, tokenizer = LSTM_tokenizer_dict['title_processed'])\n",
    "    \n",
    "    #train tokenizers for non-LSTM fields using training records from net_CSV\n",
    "    tokenizer_dict,one_hot_encoder_dict = \\\n",
    "    tokenizers_and_onehot_encoders_from_othercolumns(net_CSV,tr_val_log_dict)\n",
    "\n",
    "    #does not need to be redone\n",
    "    if False:\n",
    "        apply_tokenizers_to_db(net_CSV,tokenizer_dict)\n",
    "        \n",
    "    print(\"Done.\")\n",
    "\n",
    "    return net_CSV,tr_val_log_dict,word_to_glove_vec,\\\n",
    "    LSTM_tokenizer_dict,embedding_layers_dict,tokenizer_dict,one_hot_encoder_dict\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NIMA():\n",
    "    \"\"\"\n",
    "    Returns pre-trained keras NIMA model. Sets inpout shape to (224,224)\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        base_model = InceptionResNetV2(input_shape=(224, 224, 3), include_top=False, pooling='avg', weights=None)\n",
    "\n",
    "        x = L.Dropout(0.75)(base_model.output)\n",
    "\n",
    "        x = L.Dense(10, activation='softmax')(x)\n",
    "\n",
    "        model = Model(base_model.input, x)\n",
    "\n",
    "        model.load_weights('neural-image-assessment-master/weights/inception_resnet_weights.h5')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def NIMA_predict(img_paths,NIMA_model,batch_size):\n",
    "    \"\"\"\n",
    "    Returns a list of (mean,SD) tuples of NIMA predictions \n",
    "    for a list of image paths. Returns np.nan\n",
    "    for both mean and SD if image path is None. All images\n",
    "    will be resized to (224,224).\n",
    "    \n",
    "    img_paths: list of image full paths\n",
    "    \n",
    "    NIMA_model: pretrained keras model\n",
    "    \n",
    "    batch_size: batch size for model prediction\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    target_size = (224, 224)\n",
    "    \n",
    "    score_list = []\n",
    "    \n",
    "    img_exists_list = []\n",
    "    \n",
    "    x_list = []\n",
    "    \n",
    "    for idx,img_path in enumerate(img_paths):\n",
    "        \n",
    "        if (img_path is None):\n",
    "            \n",
    "            img_exists_list.append(False)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                img = load_img(img_path, target_size=target_size)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                img_exists_list.append(False)\n",
    "            \n",
    "                continue\n",
    "                \n",
    "            img_exists_list.append(True)\n",
    "            \n",
    "            x = img_to_array(img)\n",
    "\n",
    "            #x = np.expand_dims(x, axis=0)\n",
    "\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            x_list.append(x) \n",
    "\n",
    "    if (len(x_list) > 0):\n",
    "        \n",
    "        scores = NIMA_model.predict(np.array(x_list), batch_size=batch_size, verbose=0)\n",
    "        \n",
    "    counter = 0\n",
    "    for img_exists in img_exists_list:\n",
    "        \n",
    "        if (img_exists):\n",
    "            mean = mean_score(scores[counter,:])\n",
    "            std = std_score(scores[counter,:])\n",
    "            counter += 1\n",
    "        else:\n",
    "            mean = np.nan\n",
    "            std = np.nan\n",
    "                        \n",
    "        score_list.append((mean,std))\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def add_NIMA_score_to_database(database, train_CSV_flag = True, \\\n",
    "    zip_obj = None,NIMA_model = None,batch_size = 10,break_at = 100,\\\n",
    "    save_interval = np.int(1E4),idx_start = 0,idx_end_exclusive = None):\n",
    "    \"\"\"\n",
    "    Adds NIMA mean and SD (presumably uncertainty measure) fields to database.\n",
    "    NIMA score is image quality score, generated using this software:\n",
    "    https://github.com/titu1994/neural-image-assessment\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    num_records = database.shape[0]\n",
    "    \n",
    "    if (zip_obj is None):\n",
    "        #create zipfile object; this is slow, so do only once\n",
    "        print(\"Creating zipfile object...\")\n",
    "        created_zip_obj_flag = True\n",
    "        \n",
    "        if (train_CSV_flag):\n",
    "            zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\train_jpg.zip\"\n",
    "        else:\n",
    "            zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\test_jpg.zip\"\n",
    "        \n",
    "        zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        created_zip_obj_flag = False\n",
    "    \n",
    "    if (NIMA_model is None):\n",
    "        #load pe-trained keras NIMA model\n",
    "        print(\"Loading pre-trained keras model...\")\n",
    "        NIMA_model = load_NIMA()\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    #add NIMA score fields to database if they do not already exist\n",
    "    NIMA_score_fieldnames = ['NIMA_mean','NIMA_sd']\n",
    "    \n",
    "    print(\"Adding NIMA fieldnames to database...\")\n",
    "    for NIMA_score_fieldname in NIMA_score_fieldnames:\n",
    "        \n",
    "        if (NIMA_score_fieldname not in database.columns):\n",
    "            database[NIMA_score_fieldname] = np.zeros((num_records,),dtype = np.float32)\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    \n",
    "    print(\"Starting computation of NIMA metrics...\")\n",
    "    \n",
    "    if (idx_end_exclusive is None):\n",
    "        idx_end_exclusive = num_records\n",
    "    \n",
    "    loop_range = range(idx_start,idx_end_exclusive)    \n",
    "    \n",
    "    idx_idx = 0\n",
    "    for idx in tqdm(loop_range):\n",
    "            \n",
    "        if (idx_idx >= break_at):\n",
    "            break\n",
    "        \n",
    "        if ((idx_idx % batch_size) == 0):\n",
    "            \n",
    "            counter = 0\n",
    "            \n",
    "            loaded_jpg_full_paths = []\n",
    "        \n",
    "            idx_storage = []\n",
    "\n",
    "        jpg_id = database.loc[idx,'image']\n",
    "        \n",
    "        idx_storage.append(idx)\n",
    "        \n",
    "        #executes when no jpg file for the ad\n",
    "        if (not(isinstance(jpg_id,str)) and np.isnan(jpg_id)):\n",
    "            loaded_jpg_full_paths.append(None)\n",
    "        else:\n",
    "            loaded_jpg_full_paths.append(\\\n",
    "            extract_jpg_from_zipfileobject(zip_obj,jpg_id,verbose = False))\n",
    "            \n",
    "        if ((counter < batch_size - 1) and (idx < num_records - 1)):\n",
    "            counter += 1\n",
    "            idx_idx += 1\n",
    "            continue\n",
    "        else:\n",
    "        \n",
    "            #crnt_scores is a list of tuples, each tuple comprising (mean,SD) for corresponding image\n",
    "            crnt_scores = \\\n",
    "            NIMA_predict(img_paths = loaded_jpg_full_paths,\\\n",
    "            NIMA_model = NIMA_model,batch_size = batch_size)\n",
    "\n",
    "            for stored_idx_idx,stored_idx in enumerate(idx_storage):\n",
    "                #crnt_score is a tuple (mean,SD)\n",
    "                crnt_score = crnt_scores[stored_idx_idx]\n",
    "                for NIMA_score_idx,NIMA_score_fieldname in enumerate(NIMA_score_fieldnames):\n",
    "                    database.loc[stored_idx,NIMA_score_fieldname] = crnt_score[NIMA_score_idx]\n",
    "                \n",
    "                #delete image files from previous batch\n",
    "                if (loaded_jpg_full_paths[stored_idx_idx] is not None):\n",
    "                    os.remove(loaded_jpg_full_paths[stored_idx_idx])\n",
    "                    \n",
    "            if (((idx_idx + 1) % save_interval) == 0):\n",
    "\n",
    "                if True:\n",
    "                    database.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_net.csv')\n",
    "                elif (train_CSV_flag):\n",
    "                    database.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_train.csv')\n",
    "                else:\n",
    "                    database.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_train.csv')\n",
    "\n",
    "                note_obj = open(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\NIMA_note.txt',mode = 'wt')\n",
    "                note_obj.write(\"Last idx (inclusive) successfully saved at = {:d}.\".format(idx))\n",
    "                note_obj.close()\n",
    "                \n",
    "            idx_idx += 1\n",
    "\n",
    "    #close zipfile object\n",
    "    if (created_zip_obj_flag):\n",
    "        zip_obj.close()\n",
    "    \n",
    "    time_elapsed_s = time.clock() - start\n",
    "    \n",
    "    print(\"Time elapsed  = {:.1f} seconds\".format(time_elapsed_s))\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    \n",
    "    \n",
    "def load_InceptionResNetV2():\n",
    "    \"\"\"\n",
    "    Returns pre-trained keras InceptionResNetV2 model. Sets inpout shape to (299,299)\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        model = InceptionResNetV2(\\\n",
    "        include_top=True, weights='imagenet', input_tensor=None, \\\n",
    "        input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_VGG19():\n",
    "    \"\"\"\n",
    "    Returns pre-trained keras VGG19 model. Sets inpout shape to (224,224)\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        model = VGG19(include_top=True, \\\n",
    "        weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def object_predict(img_paths,object_classification_model,batch_size,target_size):\n",
    "    \"\"\"\n",
    "    Returns a list of lists of obhect classification (softmax) vectors. Returns np.nan\n",
    "    for both mean and SD if image path is None. All images\n",
    "    will be resized to target_size.\n",
    "    \n",
    "    img_paths: list of image full paths\n",
    "    \n",
    "    object_classification_model: pretrained keras model\n",
    "    \n",
    "    batch_size: batch size for model prediction\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    classification_vectors_list = []\n",
    "    \n",
    "    img_exists_list = []\n",
    "    \n",
    "    x_list = []\n",
    "    \n",
    "    for idx,img_path in enumerate(img_paths):\n",
    "        \n",
    "        if (img_path is None):\n",
    "            \n",
    "            img_exists_list.append(False)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                img = load_img(img_path, target_size=target_size)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                img_exists_list.append(False)\n",
    "            \n",
    "                continue\n",
    "                \n",
    "            img_exists_list.append(True)\n",
    "            \n",
    "            x = img_to_array(img)\n",
    "\n",
    "            #x = np.expand_dims(x, axis=0)\n",
    "\n",
    "            x = VGG19_preprocess_input(x)\n",
    "            \n",
    "            x_list.append(x) \n",
    "\n",
    "    if (len(x_list) > 0):\n",
    "        \n",
    "        classification_vectors = object_classification_model.predict(np.array(x_list), batch_size=batch_size, verbose=0)\n",
    "        \n",
    "    counter = 0\n",
    "    for img_exists in img_exists_list:\n",
    "        \n",
    "        if (img_exists):\n",
    "            classification_vector = classification_vectors[counter]\n",
    "            counter += 1\n",
    "        else:\n",
    "            classification_vector = np.nan\n",
    "                        \n",
    "        classification_vectors_list.append(classification_vector)\n",
    "\n",
    "    return classification_vectors_list\n",
    "\n",
    "\n",
    "def save_object_classification_vectors(database, tr_val_log_dict,\\\n",
    "    target_size, train_CSV_flag = True,\\\n",
    "    zip_obj = None,object_classification_model = None,batch_size = 10,break_at = 100,\\\n",
    "    idx_start = 0,idx_end_exclusive = None):\n",
    "    \"\"\"\n",
    "    Saves object classification vector np.array as PKL file named with\n",
    "    corresponding image_ID (obtained from input database).\n",
    "    \n",
    "    database: should be net_CSV database\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    if (zip_obj is None):\n",
    "        #create zipfile object; this is slow, so do only once\n",
    "        print(\"Creating zipfile object...\")\n",
    "        created_zip_obj_flag = True\n",
    "        \n",
    "        if (train_CSV_flag):\n",
    "            zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\train_jpg.zip\"\n",
    "        else:\n",
    "            zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\test_jpg.zip\"\n",
    "        \n",
    "        zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        created_zip_obj_flag = False\n",
    "    \n",
    "    if (object_classification_model is None):\n",
    "        #load pe-trained keras NIMA model\n",
    "        print(\"Loading pre-trained keras model...\")\n",
    "        #object_classification_model = load_InceptionResNetV2()\n",
    "        object_classification_model = load_VGG19()\n",
    "        print(\"Done.\")\n",
    "        \n",
    "    if (train_CSV_flag):\n",
    "        database_indices = database.index[\\\n",
    "        np.logical_or(tr_val_log_dict['training_logical'],tr_val_log_dict['validation_logical'])]\n",
    "        \n",
    "    else:\n",
    "        database_indices =  database.index[tr_val_log_dict['test_logical']]\n",
    "    \n",
    "    num_records = database_indices.shape[0]\n",
    "    \n",
    "    print(\"Starting computation of object classification vectors...\")\n",
    "    \n",
    "    if (idx_end_exclusive is None):\n",
    "        idx_end_exclusive = num_records\n",
    "    \n",
    "    loop_range = range(idx_start,idx_end_exclusive)    \n",
    "    \n",
    "    idx_idx = 0\n",
    "    for idx in tqdm(loop_range):\n",
    "            \n",
    "        if (idx_idx >= break_at):\n",
    "            break\n",
    "        \n",
    "        if ((idx_idx % batch_size) == 0):\n",
    "            \n",
    "            counter = 0\n",
    "            \n",
    "            loaded_jpg_full_paths = []\n",
    "        \n",
    "            idx_storage = []\n",
    "            \n",
    "            jpg_id_storage = []\n",
    "\n",
    "        jpg_id = database.loc[database_indices[idx],'image']\n",
    "        \n",
    "        idx_storage.append(idx)\n",
    "        \n",
    "        jpg_id_storage.append(jpg_id)\n",
    "        \n",
    "        #executes when no jpg file for the ad\n",
    "        if (not(isinstance(jpg_id,str)) and np.isnan(jpg_id)):\n",
    "            loaded_jpg_full_paths.append(None)\n",
    "        else:\n",
    "            loaded_jpg_full_paths.append(\\\n",
    "            extract_jpg_from_zipfileobject(zip_obj,jpg_id,verbose = False))\n",
    "            \n",
    "        if ((counter < batch_size - 1) and (idx < num_records - 1)):\n",
    "            counter += 1\n",
    "            idx_idx += 1\n",
    "            continue\n",
    "        else:\n",
    "        \n",
    "            #classification_vectors_list is a list of np arrays, \n",
    "            #each array being a softmax vector of object classifications \n",
    "            #for corresponding image\n",
    "            classification_vectors_list = \\\n",
    "            object_predict(img_paths = loaded_jpg_full_paths,\\\n",
    "            object_classification_model = object_classification_model,batch_size = batch_size,\\\n",
    "            target_size = target_size)\n",
    "\n",
    "            for stored_idx_idx,(stored_idx,jpg_id) in enumerate(zip(idx_storage,jpg_id_storage)):\n",
    "            \n",
    "                crnt_classification_vector = classification_vectors_list[stored_idx_idx]\n",
    "\n",
    "                if (loaded_jpg_full_paths[stored_idx_idx] is not None):\n",
    "\n",
    "                    object_classification_save_file = os.path.join(\\\n",
    "                    OBJECT_CLASSIFICATION_SAVE_DIR,jpg_id + '.pkl')\n",
    "\n",
    "                    with open(object_classification_save_file,mode = 'wb') as object_classification_fobj:\n",
    "                        pickle.dump(crnt_classification_vector, object_classification_fobj)\n",
    "\n",
    "                    #delete image files from previous batch\n",
    "                    os.remove(loaded_jpg_full_paths[stored_idx_idx])\n",
    "                \n",
    "            idx_idx += 1\n",
    "\n",
    "    #close zipfile object\n",
    "    if (created_zip_obj_flag):\n",
    "        zip_obj.close()\n",
    "    \n",
    "    time_elapsed_s = time.clock() - start\n",
    "    \n",
    "    print(\"Time elapsed  = {:.1f} seconds\".format(time_elapsed_s))\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    \n",
    "    \n",
    "def load_object_classification_vectors(jpg_id_list):\n",
    "    \"\"\"\n",
    "    Returns list of object classification vectors in order corresponding to jpg_id_list.\n",
    "    \"\"\"\n",
    "\n",
    "    classification_vector_list = []\n",
    "    \n",
    "    dummy = np.zeros((NUM_OBJECT_CLASSES,),dtype = np.float32)\n",
    "    \n",
    "    for jpg_id in jpg_id_list:\n",
    "        \n",
    "        if (isinstance(jpg_id,str)):\n",
    "\n",
    "            object_classification_load_file = os.path.join(OBJECT_CLASSIFICATION_SAVE_DIR,jpg_id + '.pkl')\n",
    "\n",
    "            with open(object_classification_load_file,mode = 'rb') as object_classification_fobj:\n",
    "                object_classification_vector = pickle.load(object_classification_fobj)\n",
    "            \n",
    "            if (isinstance(object_classification_vector,float)):\n",
    "                \n",
    "                classification_vector_list.append(dummy)\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                classification_vector_list.append(object_classification_vector)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            classification_vector_list.append(dummy)\n",
    "            \n",
    "    return classification_vector_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_str_separate_wrapper(str_in):\n",
    "    \"\"\"\n",
    "    If any numeral is in string, pass on to number_str_separate(). Otherwise,\n",
    "    return string.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeral_in_string_flag = False\n",
    "    \n",
    "    for n in NUMERALS:\n",
    "        if (n in str_in):\n",
    "            numeral_in_string_flag = True\n",
    "            break\n",
    "    \n",
    "    if (numeral_in_string_flag):\n",
    "        str_out = number_str_separate(str_in)\n",
    "        return str_out\n",
    "    else:\n",
    "        return str_in\n",
    "        \n",
    "        \n",
    "def number_str_separate(str_in,previous_char_was_numeral = None,\\\n",
    "    previous_char_was_space = False,previous_char_was_decimal = False,\\\n",
    "    crnt_run_began_with_cap_eng = False):\n",
    "    \"\"\"\n",
    "    Adds spaces between runs of consecutive numerals and adjacent substrings.\n",
    "    \n",
    "    Spaces are not intercalated between English alphabetic characters followed by numerals.\n",
    "    \n",
    "    Spaces are not intercalated before or after decimals.\n",
    "    \n",
    "    Decimals are replaced with DECIMAL_REPLACEMENT_CHAR to allow separate processing of periods.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    str_out = number_str_separate('I owe him 20bucks.')\n",
    "    print(str_out)\n",
    "    \n",
    "    I owe him 20 bucks.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(str_in,str))):\n",
    "        raise TypeError(\"str_in input should be a str, but instead was a {}\".format(type(str_in)))\n",
    "        \n",
    "    if (previous_char_was_numeral is None):\n",
    "        crnt_run_began_with_cap_eng = str_in[0] in ENGLISH_LETTERS\n",
    "        \n",
    "    if ((len(str_in) > 0) and (str_in[0] in NUMERALS)):\n",
    "        if (previous_char_was_numeral is None):\n",
    "            spacer = ''\n",
    "        elif (previous_char_was_numeral):\n",
    "            spacer = ''\n",
    "        elif (not(crnt_run_began_with_cap_eng) and \\\n",
    "        not(previous_char_was_space) and not(previous_char_was_decimal)):\n",
    "            spacer = ' '\n",
    "        else:\n",
    "            spacer = ''\n",
    "        previous_char_was_numeral = True\n",
    "        previous_char_was_space = False\n",
    "        previous_char_was_decimal = False\n",
    "    else:\n",
    "        if (previous_char_was_numeral is None):\n",
    "            spacer = ''\n",
    "        elif (not(crnt_run_began_with_cap_eng) and \\\n",
    "        previous_char_was_numeral \\\n",
    "        and (len(str_in) > 0) and (str_in[0] != '.')):\n",
    "            spacer = ' '\n",
    "        else:\n",
    "            spacer = ''\n",
    "            \n",
    "        if (len(str_in) > 0):\n",
    "            if (previous_char_was_numeral) and (str_in[0] == '.'):\n",
    "                if (len(str_in) > 1):\n",
    "                    str_in = DECIMAL_REPLACEMENT_CHAR + str_in[1:]\n",
    "                previous_char_was_decimal = True\n",
    "            else:\n",
    "                previous_char_was_decimal = False\n",
    "                \n",
    "            if (previous_char_was_space):\n",
    "                crnt_run_began_with_cap_eng = str_in[0] in ENGLISH_LETTERS\n",
    "            \n",
    "            previous_char_was_numeral = False\n",
    "            previous_char_was_space = ((str_in[0] == ' ') or (str_in[0] == '\\n'))\n",
    "             \n",
    "                        \n",
    "    #print(str_in[0],previous_char_was_space)\n",
    "        \n",
    "    if (len(str_in) > 1):\n",
    "        str_recursive = number_str_separate(str_in[1:],\\\n",
    "        previous_char_was_numeral,previous_char_was_space,\\\n",
    "        previous_char_was_decimal,crnt_run_began_with_cap_eng)\n",
    "    else:\n",
    "        str_recursive = ''\n",
    "        \n",
    "    if (len(str_in) > 0):\n",
    "        \n",
    "        return spacer + str_in[0] + str_recursive\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return str_in\n",
    "    \n",
    "    \n",
    "def remove_spaces(data):\n",
    "    \"\"\"\n",
    "    Removes spaces and newlines from data that have casted to str.\n",
    "    \n",
    "    texts: list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(data,list))):\n",
    "        raise TypeError(\"data input should be a list, but instead was a {}\".format(type(texts)))\n",
    "        \n",
    "    texts_without_spaces = []\n",
    "    \n",
    "    for s in data:\n",
    "        texts_without_spaces.append(str(s).replace(' ','').replace('\\n',''))\n",
    "        \n",
    "    return texts_without_spaces\n",
    "    \n",
    "    \n",
    "def enforce_list_elements_to_str(list_in):\n",
    "    \"\"\"\n",
    "    Makes sure all list elements are of type str.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(list_in,list))):\n",
    "        raise TypeError(\"list_in input should be a list, but instead was a {}\".format(type(list_in)))\n",
    "    \n",
    "    return list(map(lambda x: str(x),list_in))\n",
    "    \n",
    "    \n",
    "def return_trained_tokenizer(texts,tokenizer = None,filters = '\\n'):\n",
    "    \"\"\"\n",
    "    trains keras tokenizer on texts\n",
    "    \n",
    "    texts: list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(texts,list))):\n",
    "        raise TypeError(\"texts input should be a list, but instead was a {}\".format(type(texts)))\n",
    "        \n",
    "    texts = enforce_list_elements_to_str(texts)\n",
    "    \n",
    "    if tokenizer == None:\n",
    "        tokenizer = Tokenizer(filters = filters)\n",
    "    \n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    return tokenizer\n",
    "   \n",
    "    \n",
    "def return_word2index_dict(tokenizer):\n",
    "    \n",
    "    return tokenizer.word_index\n",
    "\n",
    "\n",
    "def word2index_dict_2_index2word_dict(word2index_dict):\n",
    "    \"\"\"\n",
    "    creates dictionary with index keys and word values\n",
    "    from dictionary with word keys and index values\n",
    "    \"\"\"\n",
    "    \n",
    "    return \\\n",
    "    {value:key for key,value in word2index_dict.items()}\n",
    "    \n",
    "        \n",
    "def return_tokenized_sequences(tokenizer,texts):\n",
    "    \"\"\"\n",
    "    texts: list of strings comprising concatenated tokens\n",
    "    \n",
    "    sequences: list of lists, the latter being \n",
    "    the tokens mapped onto their word_index value\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(texts,list))):\n",
    "        raise TypeError(\"texts input should be a list, but instead was a {}\".format(type(texts)))\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "\n",
    "def check_for_singletons(list_of_lists):\n",
    "    \"\"\"\n",
    "    checks for existence of single element in every interior list of list_of_lists\n",
    "    \"\"\"\n",
    "\n",
    "    counter = 0\n",
    "    for idx,interior_list in enumerate(list_of_lists):\n",
    "\n",
    "        if (len(interior_list) > 1):\n",
    "            raise ValueError('len(interior_list) = {:d} > 1'.format(len(interior_list)))\n",
    "            \n",
    "        elif (len(interior_list) == 0):\n",
    "            #use value of 0 to represent values not mapped by original tokenizer\n",
    "            counter += 1\n",
    "            interior_list.append(0)\n",
    "            \n",
    "    print(\"total # of empty tokens found = {:d}\".format(counter))\n",
    "        \n",
    "\n",
    "def list_of_lists_of_singletons_to_array(list_of_lists_of_singletons,dtype):\n",
    "    \n",
    "    singleton_array = np.zeros((len(list_of_lists_of_singletons),1),dtype = dtype)\n",
    "        \n",
    "    for idx,list_of_singleton in enumerate(list_of_lists_of_singletons):\n",
    "\n",
    "        assert(len(list_of_singleton) == 1),print(len(list_of_singleton),list_of_singleton)\n",
    "\n",
    "        singleton_array[idx] = list_of_singleton[0]\n",
    "\n",
    "    return singleton_array\n",
    "\n",
    "\n",
    "def tokenizer_for_LSTM(database,column_to_tokenize,tr_val_log_dict,dtype = np.int64):\n",
    "    \"\"\"\n",
    "    Returns a trained keras tokenizer instance. This tokenizer\n",
    "    will have been trained using the train records of the column_to_tokenize field.\n",
    "\n",
    "    database: competition train CSV (which comprises train and validation records)\n",
    "    \n",
    "    column_to_tokenize: database fieldname to tokenize\n",
    "    \n",
    "    tr_val_log_dict: dictionary with keys 'training_logical\" and\n",
    "    'validation_logical' and values of bool arrays that indicates the\n",
    "    training and validation records, respectively.\n",
    "    \n",
    "    dtype: dtype of \n",
    "    \"\"\"\n",
    "    \n",
    "    assert(column_to_tokenize in database.columns)\n",
    "        \n",
    "    #train only using training records of database\n",
    "    texts_tr_only = list(database.loc[tr_val_log_dict['training_logical'],column_to_tokenize])\n",
    "\n",
    "    tokenizer = return_trained_tokenizer(texts_tr_only,tokenizer = None,filters = '\\n')\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def add_string_length_field(database,column_to_assess):\n",
    "    \"\"\"\n",
    "    Adds field with the number of spaced\n",
    "    delimited elements of fieldname field to database\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert(column_to_assess in database.columns)\n",
    "    \n",
    "    column_to_add = column_to_assess + '_length' \n",
    "    \n",
    "    num_records = database.shape[0]\n",
    "    \n",
    "    len_str = np.zeros((num_records,),dtype = np.int32)\n",
    "        \n",
    "    for idx in tqdm(range(num_records)):\n",
    "        \n",
    "        crnt_str = str(database[column_to_assess].iloc[idx])\n",
    "        \n",
    "        len_str[idx] = len(crnt_str.split(' ')) \n",
    "        \n",
    "    database[column_to_add] = len_str\n",
    "        \n",
    "\n",
    "def determine_max_len_description(database,tr_val_log_dict,verbose = False):\n",
    "    \"\"\"\n",
    "    Determines maximum length of processed description (as number of space-delimited\n",
    "    elements comprising the processed description) from the train records of the competition\n",
    "    train CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    column_to_tokenize = 'description_processed'\n",
    "    \n",
    "    assert(column_to_tokenize in database.columns)\n",
    "        \n",
    "    #train only using training records of database\n",
    "    texts_tr_only = list(database.loc[tr_val_log_dict['training_logical'],column_to_tokenize])\n",
    "    \n",
    "    item_id_tr_only = list(database.loc[tr_val_log_dict['training_logical'],'item_id'])\n",
    "    \n",
    "    texts_tr_only = enforce_list_elements_to_str(texts_tr_only)\n",
    "    \n",
    "    max_len = 0\n",
    "    max_len_str = None\n",
    "    max_len_item_id = None\n",
    "    \n",
    "    for t,item_id in zip(texts_tr_only,item_id_tr_only):\n",
    "        \n",
    "        num_space_delim_elements_in_t = len(t.split(' ')) \n",
    "        \n",
    "        if (num_space_delim_elements_in_t > max_len):\n",
    "            max_len = num_space_delim_elements_in_t\n",
    "            max_len_str = t\n",
    "            max_len_item_id = item_id\n",
    "     \n",
    "    if (verbose):\n",
    "        print(\"maximum length of processed descriptions from train records = {:d}.\".format(max_len))\n",
    "        print(\"corresponding item id = {:s}.\".format(max_len_item_id))\n",
    "        print(\"corresponding string:\\n{:s}.\".format(max_len_str))\n",
    "            \n",
    "    return max_len\n",
    "        \n",
    "\n",
    "def tokenizers_and_onehot_encoders_from_othercolumns(database,\\\n",
    "    tr_val_log_dict,\\\n",
    "    columns_to_tokenize = ['parent_category_name','category_name',\\\n",
    "    'param_1', 'param_2','param_1', 'param_3','user_type'],dtype = np.int16):\n",
    "    \"\"\"\n",
    "    (i) Returns a dictionary of keras tokenizer instances with keys being\n",
    "    columns_to_tokenize. Each tokenizers will have been trained using the\n",
    "    de-spaced (so as to produce a single token per value) strings from the \n",
    "    corresponding fields of the training records of the database.\n",
    "    (ii) Returns a dictionary of sklearn one-hot-encoders. These encoders\n",
    "    will have been trained on the tokenized sequences obtained from (i).\n",
    "    (iii) Modifies in-place the passed database by adding new fields \n",
    "    for tokenized values.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer_dict = {}\n",
    "    one_hot_encoder_dict = {}\n",
    "\n",
    "    for col in tqdm(columns_to_tokenize):\n",
    "        print(\"\\n{:s}\".format(col))\n",
    "        \n",
    "        #train only using training records of database\n",
    "        data = list(database.loc[tr_val_log_dict['training_logical'],col])\n",
    "\n",
    "        texts_tr_only = remove_spaces(data)\n",
    "\n",
    "        tokenizer = return_trained_tokenizer(texts_tr_only,tokenizer = None,filters = '\\n')\n",
    "\n",
    "        tokenizer_dict[col] = tokenizer\n",
    "\n",
    "        #apply tokenizer to all records of database, which comprises\n",
    "        #both training, validation, and test records\n",
    "        data = list(database.loc[:,col])\n",
    "\n",
    "        texts = remove_spaces(data)\n",
    "        \n",
    "        tokenized_sequences = return_tokenized_sequences(tokenizer,texts)\n",
    "        \n",
    "        check_for_singletons(tokenized_sequences)\n",
    "        \n",
    "        #converting tokenized_sequences from list of lists to np.array\n",
    "        tokenized_sequences = list_of_lists_of_singletons_to_array(tokenized_sequences,dtype = dtype)\n",
    "        \n",
    "        database['tokenized_' + col] = tokenized_sequences\n",
    "\n",
    "        #adding 1 to RHS of n_values so as to reserve code of 0 for any empty \n",
    "        #token or token that did not appear in training records\n",
    "        one_hot_encoder = OneHotEncoder(n_values = len(tokenizer.word_index) + 1, dtype = dtype) \n",
    "\n",
    "        #fit one_hot_encoder only using training records\n",
    "        tokenized_sequences_tr_only = return_tokenized_sequences(tokenizer,texts_tr_only)\n",
    "        \n",
    "        check_for_singletons(tokenized_sequences_tr_only)\n",
    "        \n",
    "        #converting tokenized_sequences from list of lists to np.array\n",
    "        tokenized_sequences_tr_only = list_of_lists_of_singletons_to_array(tokenized_sequences_tr_only,dtype = dtype)\n",
    "        \n",
    "        one_hot_encoder.fit(tokenized_sequences_tr_only)\n",
    "\n",
    "        one_hot_encoder_dict[col] = one_hot_encoder\n",
    "\n",
    "    return tokenizer_dict,one_hot_encoder_dict\n",
    "\n",
    "\n",
    "def apply_tokenizers_to_db(database,\\\n",
    "    tokenizer_dict,\\\n",
    "    columns_to_tokenize = ['parent_category_name','category_name',\\\n",
    "    'param_1', 'param_2','param_1', 'param_3','user_type'],dtype = np.int16):\n",
    "    \"\"\"\n",
    "    Modifies in-place the passed database (which should not be the \n",
    "    competition train database) by adding new fields \n",
    "    for tokenized values using tokenizers trained using the training \n",
    "    records of the train database.\n",
    "    \n",
    "    ***Note: this does not handle tokenization of 'descriptions' field.\n",
    "    \n",
    "    database: any database other than original train database\n",
    "    \n",
    "    tokenizer_dict: dictionary of tokenizers that were trained using \n",
    "    training records of train database\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in tqdm(columns_to_tokenize):\n",
    "        print(\"\\n{:s}\".format(col))\n",
    "        \n",
    "        #apply tokenizer to all records of database\n",
    "        data = list(database.loc[:,col])\n",
    "\n",
    "        texts = remove_spaces(data)\n",
    "        \n",
    "        tokenized_sequences = return_tokenized_sequences(tokenizer_dict[col],texts)\n",
    "        \n",
    "        check_for_singletons(tokenized_sequences)\n",
    "        \n",
    "        #converting tokenized_sequences from list of lists to np.array\n",
    "        tokenized_sequences = list_of_lists_of_singletons_to_array(tokenized_sequences,dtype = dtype)\n",
    "        \n",
    "        database['tokenized_' + col] = tokenized_sequences\n",
    "\n",
    "\n",
    "def return_word2glovevec_dict(\\\n",
    "    glove_filename = r\"C:\\Users\\me\\Documents\\AvitoCompetition\\data\\glove\\glove.twitter.27B.50d.txt\"):\n",
    "\n",
    "    word_to_glove_vec = {} \n",
    "\n",
    "    with open(glove_filename,mode = 'rt', encoding=\"utf-8\") as glove_obj:\n",
    "\n",
    "        for line_idx,line in enumerate(glove_obj):\n",
    "            \n",
    "            if line_idx == 0:\n",
    "                continue\n",
    "                \n",
    "            words = line.strip().split(' ')\n",
    "            \n",
    "            if True:\n",
    "                try:\n",
    "                    vec = list(map(lambda x: np.float32(x),words[1:]))\n",
    "                    word_to_glove_vec[words[0]] = np.array(vec,dtype = np.float32)\n",
    "                except:\n",
    "                    print(words[1:])\n",
    "                    sys.exit()\n",
    "            else:\n",
    "                print(words[0])\n",
    "                print(words[1:10])\n",
    "            \n",
    "                if line_idx == 50:\n",
    "                    break\n",
    "\n",
    "    return word_to_glove_vec\n",
    "\n",
    "\n",
    "def split_sentences(texts):\n",
    "    \"\"\"\n",
    "    texts: list of strings comprising concatenated tokens\n",
    "    \n",
    "    spacified_texts: list of lists of strings that are newline-\n",
    "    separated versions of original strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(texts,list))):\n",
    "        raise TypeError(\"texts input should be a list, but instead was a {}\".format(type(texts)))\n",
    "        \n",
    "    text_split_into_sentences = []\n",
    "    \n",
    "    for string in texts:\n",
    "        \n",
    "        #string = string.replace('/\\n','.')\n",
    "        \n",
    "        split_string = string.split('/\\n')\n",
    "        \n",
    "        for idx,_ in enumerate(split_string):\n",
    "            \n",
    "            #replace strings that only comprise spaces and periods with empty string\n",
    "            if (split_string[idx].replace(' ','').replace('.','') == ''):\n",
    "                \n",
    "                split_string[idx] = ''\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                pass\n",
    "\n",
    "                #add period to end of each element of split_string\n",
    "                #split_string[idx] += '.'\n",
    "\n",
    "        text_split_into_sentences.append(split_string)\n",
    "        \n",
    "    return text_split_into_sentences\n",
    "        \n",
    "    \n",
    "def spacify_punctuation(texts):\n",
    "    \"\"\"\n",
    "    texts: list of strings or list of list of strings comprising concatenated tokens\n",
    "    \n",
    "    spacified_texts: list of strings or list of list of strings with space added before\n",
    "    and after punctuation characters\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(texts,list))):\n",
    "        raise TypeError(\"texts input should be a list, but instead was a {}\".format(type(texts)))\n",
    "    \n",
    "    #check if texts is list of list of strings\n",
    "    if (isinstance(texts[0],list)):\n",
    "        \n",
    "        spacified_texts = []\n",
    "        for sublist in texts:\n",
    "            spacified_sublist = []\n",
    "            for string in sublist:\n",
    "                for punctuation in PUNCTUATION_MARKS:\n",
    "                    string = string.replace(punctuation, ' ' + punctuation + ' ')\n",
    "\n",
    "                spacified_sublist.append(string)\n",
    "                \n",
    "            spacified_texts.append(spacified_sublist)\n",
    "        \n",
    "    elif (isinstance(texts[0],str)):\n",
    "\n",
    "        spacified_texts = []\n",
    "        for string in texts:\n",
    "            for punctuation in PUNCTUATION_MARKS:\n",
    "                string = string.replace(punctuation, ' ' + punctuation + ' ')\n",
    "\n",
    "            spacified_texts.append(string)\n",
    "            \n",
    "    else:\n",
    "        raise TypeError(\"texts[0] should be either a list or str, but instead was a {}\".format(type(texts[0])))\n",
    "        \n",
    "\n",
    "    return spacified_texts\n",
    "\n",
    "\n",
    "def preprocess_fields_for_tokenizing(database,\\\n",
    "fieldnames_to_preprocess = ['description','title']): \n",
    "    \"\"\"\n",
    "    preprocess 'description' field - no need to redo if desired field exists in CSV\n",
    "    \"\"\"\n",
    "\n",
    "    for fieldname in fieldnames_to_preprocess:\n",
    "\n",
    "        if (fieldname + '_processed' not in database.columns):\n",
    "\n",
    "            print(\"Now pre-processing fieldname: {:s}\".format(fieldname))\n",
    "\n",
    "            strings_for_tokenizing = preprocess_string_fields_for_tokenizing(database,fieldname)\n",
    "\n",
    "            database[fieldname + '_processed'] = strings_for_tokenizing    \n",
    "\n",
    "\n",
    "def print_list_of_strings(texts):\n",
    "    \"\"\"\n",
    "    prints list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(texts,list))):\n",
    "        raise TypeError(\"texts input should be a list, but instead was a {}\".format(type(texts)))\n",
    "        \n",
    "    for string in texts:\n",
    "        print(string)\n",
    "\n",
    "        \n",
    "def print_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    prints list of lists\n",
    "    \"\"\"\n",
    "    \n",
    "    if (not(isinstance(list_of_lists,list))):\n",
    "        raise TypeError(\"list_of_lists input should be a list, but instead was a {}\".format(type(list_of_lists)))\n",
    "        \n",
    "    for list_ in list_of_lists:\n",
    "        print(list_)\n",
    "        \n",
    "        \n",
    "def print_words_from_sequence(tokenizer,sequences):\n",
    "    \"\"\"\n",
    "    prints space delimited tokens corresponding to sequences\n",
    "    \n",
    "    tokenizer: trained Tokenizer object\n",
    "    \n",
    "    sequences: a list of lists, the latter having elements\n",
    "    that are indices of tokenizer word_index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    word2index_dict = return_word2index_dict(tokenizer)\n",
    "    \n",
    "    index2word_dict = word2index_dict_2_index2word_dict(word2index_dict)\n",
    "\n",
    "    for sequence in sequences:\n",
    "        print(\"\")\n",
    "        for seq_idx,word_idx in enumerate(sequence):\n",
    "            if (seq_idx == len(sequence) - 1):\n",
    "                end_str = '\\n'\n",
    "            else:\n",
    "                end_str = ''\n",
    "                \n",
    "            print(index2word_dict[word_idx] + ' ',end = end_str)\n",
    "            \n",
    "            \n",
    "def test_tokenization(tokenizer,sequences,texts):\n",
    "    \"\"\"\n",
    "    Checks that texts used to train tokenizer are isomorphic to\n",
    "    the tokenizer indices.\n",
    "    \n",
    "    tokenizer: trained Tokenizer object\n",
    "    \n",
    "    texts: list of strings that were used to train tokenizer\n",
    "    \n",
    "    sequences: a list of lists, the latter having elements\n",
    "    that are indices of tokenizer word_index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(sequences) == len(texts)),print(\"The lengths of sequences and texts must be the same.\")\n",
    "    \n",
    "    word2index_dict = return_word2index_dict(tokenizer)\n",
    "    \n",
    "    index2word_dict = word2index_dict_2_index2word_dict(word2index_dict)\n",
    "\n",
    "    for seq_idx,sequence in enumerate(sequences):\n",
    "        print(\"\")\n",
    "        text_from_sequence = []\n",
    "        for word_idx in sequence:\n",
    "            text_from_sequence.append(index2word_dict[word_idx])\n",
    "            \n",
    "        text_from_sequence = ' '.join(text_from_sequence)\n",
    "        \n",
    "        text_to_compare = texts[seq_idx].lower().replace('\\n','')\n",
    "        for text1,text2 in zip(text_to_compare.split(),text_from_sequence.split()): \n",
    "            if (not(text1 == text2)):\n",
    "                print(\"mismatch detected for:\\n(original text) '{:s}'\\n(text from sequence) '{:s}':\",\\\n",
    "                text1,text2)\n",
    "                print(text2)\n",
    "                print(text_from_sequence)\n",
    "                print(text_to_compare)\n",
    "                return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "        \n",
    "def pretrained_embedding_layer(word_to_vec_map, tokenizer):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    tokenizer -- trained keras Tokenizer object (trained only on training records of \n",
    "    competition train CSV)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\".\"].shape[0]      # define dimensionality of your GloVe word vectors\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim),dtype = np.float32)\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        word_vec = word_to_vec_map.get(word)\n",
    "        if (word_vec is not None):\n",
    "            #words that are not keys in word_to_vec_map\n",
    "            #will be assigned vector of all zeros\n",
    "            emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). \n",
    "    #Make sure to set trainable=False. \n",
    "    embedding_layer = L.Embedding(input_dim = vocab_len,output_dim = emb_dim,trainable = False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def preprocess_string_fields_for_tokenizing(database,fieldname):\n",
    "    \"\"\"\n",
    "    Returns list of strings originating from 'description' field of database that\n",
    "    have been pre-processed for tokenizing. CSV argument is not modified.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(fieldname in database.columns)\n",
    "\n",
    "    start = time.clock()\n",
    "\n",
    "    in_embedding = 0\n",
    "    not_in_embedding = 0\n",
    "\n",
    "    #original_strings = []\n",
    "    strings_for_tokenizing = []\n",
    "\n",
    "    tokens_not_in_embedding = set()\n",
    "\n",
    "    #lemmatization improves proportion of tokens in pre-trained\n",
    "    #glove vector dict, but takes too much time.\n",
    "    try_lemmatization_flag = False\n",
    "    try_number_split_flag = True\n",
    "\n",
    "    print_flag = False\n",
    "\n",
    "    if (try_lemmatization_flag):\n",
    "        m = Mystem()\n",
    "    \n",
    "    for a in tqdm(range(database.shape[0])):\n",
    "\n",
    "        if True:\n",
    "\n",
    "            string_for_tokenizing = []\n",
    "\n",
    "            s = str(database.loc[a,fieldname])\n",
    "\n",
    "            #original_strings.append(s)\n",
    "\n",
    "            #split_sentences() does not split using spaces, but rather periods and new lines.\n",
    "            #That is why I split t by spaces below.\n",
    "            s2 = split_sentences([s])[0]\n",
    "\n",
    "            for t in s2:\n",
    "                if (t == ''):\n",
    "                    continue\n",
    "                for w in t.split():\n",
    "\n",
    "                    w = w.lower()\n",
    "\n",
    "                    if False and (word_to_glove_vec.get(w) is not None):\n",
    "                        string_for_tokenizing.append(w)\n",
    "                        in_embedding += 1\n",
    "                    else:\n",
    "\n",
    "                        lemmatized_ok_flag = False\n",
    "                        number_split_ok_flag = False\n",
    "\n",
    "                        if (try_number_split_flag):\n",
    "                            w = w.replace(DECIMAL_REPLACEMENT_CHAR,'')\n",
    "                            number_separated_w = number_str_separate_wrapper(w)\n",
    "\n",
    "                            number_separated_w = spacify_punctuation([number_separated_w])[0]\n",
    "\n",
    "                            number_separated_w = number_separated_w.replace(DECIMAL_REPLACEMENT_CHAR,'.')\n",
    "\n",
    "                            for number_separated_w_piece in number_separated_w.split():\n",
    "\n",
    "                                string_for_tokenizing.append(number_separated_w_piece)\n",
    "\n",
    "                                if (word_to_glove_vec.get(number_separated_w_piece) is not None):\n",
    "                                    number_split_ok_flag = True\n",
    "                                    in_embedding += 1\n",
    "                                elif (word_to_glove_vec.get(number_separated_w_piece.lower()) is not None):\n",
    "                                    number_split_ok_flag = True\n",
    "                                    in_embedding += 1\n",
    "\n",
    "                        #try lemmatization\n",
    "                        if (try_lemmatization_flag and not(number_split_ok_flag)):\n",
    "                            lemmas = m.lemmatize(w)\n",
    "                            for lemma_piece in lemmas:\n",
    "                                if (lemma_piece != '\\n'):\n",
    "                                    if (word_to_glove_vec.get(lemma_piece) is not None):\n",
    "                                        in_embedding += 1\n",
    "                                        lemmatized_ok_flag = True\n",
    "\n",
    "                        if ((not(lemmatized_ok_flag)) and (not(number_split_ok_flag))):\n",
    "\n",
    "                            string_for_tokenizing.append(w)\n",
    "\n",
    "                            not_in_embedding += 1\n",
    "\n",
    "                            tokens_not_in_embedding = tokens_not_in_embedding.union({w})\n",
    "\n",
    "            strings_for_tokenizing.append(' '.join(string_for_tokenizing))\n",
    "\n",
    "    if print_flag:\n",
    "        print(\"\\n\\ntokens_not_in_embedding:\\n\",tokens_not_in_embedding)\n",
    "\n",
    "        for s_for_tok,orig in zip(strings_for_tokenizing,original_strings):\n",
    "            print(\"\\n\\noriginal string:\\n\",orig)\n",
    "            print(\"\\nstring for tokenizing\\n\",s_for_tok)\n",
    "\n",
    "    print(\"\\n% of tokens in embedding = {:.2f}\".format(100*in_embedding/(in_embedding + not_in_embedding)))\n",
    "\n",
    "\n",
    "    print(\"time elapsed = {:.1f} s\".format(time.clock() - start))\n",
    "    \n",
    "    return strings_for_tokenizing\n",
    "\n",
    "\n",
    "def return_training_and_validation_logical_dict(database,num_days_for_validation = 12):\n",
    "    \"\"\"\n",
    "    Returns dictionary with keys (as appropriate) \n",
    "    (i) 'training_logical'\n",
    "    (i) 'validation_logical'\n",
    "    (i) 'test_logical'\n",
    "    whose respective values are bool arrays for training and validation\n",
    "    records, respectively.\n",
    "    \n",
    "    database: should be concatenation if train and test CSVs \n",
    "    \"\"\"\n",
    "    \n",
    "    tr_val_log_dict = {'training_logical': [],'validation_logical': [],'test_logical': []}\n",
    "    \n",
    "    train_CSV_logical = (database['source'] == 'competition train CSV')\n",
    "    test_CSV_logical = (database['source'] == 'competition test CSV')\n",
    "    \n",
    "    #get 1 week of validation data\n",
    "    validation_start_date = \\\n",
    "    database.loc[train_CSV_logical,'activation_date'].max() \\\n",
    "    - timedelta(days= (num_days_for_validation - 1))\n",
    "\n",
    "    tr_val_log_dict['training_logical'] = \\\n",
    "    np.logical_and(database.loc[:,'activation_date'] < validation_start_date,train_CSV_logical)\n",
    "    \n",
    "    tr_val_log_dict['validation_logical'] = \\\n",
    "    np.logical_and(database.loc[:,'activation_date'] >= validation_start_date,train_CSV_logical)\n",
    "    \n",
    "    tr_val_log_dict['test_logical'] = test_CSV_logical\n",
    "    \n",
    "    assert(tr_val_log_dict['training_logical'].sum() + \\\n",
    "          tr_val_log_dict['validation_logical'].sum() + \\\n",
    "          tr_val_log_dict['test_logical'].sum() == database.shape[0])\n",
    "    \n",
    "    return tr_val_log_dict\n",
    "\n",
    "\n",
    "def report_na(database,verbose_columns = []):\n",
    "    \"\"\"\n",
    "    Prints # and % of null records per column. Prints out null observations for verbose_columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_num_records = database.shape[0] \n",
    "    \n",
    "    for c in database.columns:\n",
    "        \n",
    "        crnt_isna = database[c].isna()\n",
    "        \n",
    "        crnt_num_unique = net_CSV[c].unique().shape[0]\n",
    "        \n",
    "        print(\"\\n# (%) nulls for column {:s} = {:d} ({:.2f}%); # unique values = {:d}\".format(\\\n",
    "        c,crnt_isna.sum(),100*crnt_isna.sum()/total_num_records,crnt_num_unique))\n",
    "        \n",
    "        if (c in verbose_columns):\n",
    "            print(database.loc[crnt_isna,c])\n",
    "            \n",
    "            \n",
    "def add_day_of_week_field(database):\n",
    "    \"\"\"\n",
    "    Adds 'day_of_week' field to database if it does not already exist. \n",
    "    \"\"\"\n",
    "    \n",
    "    if ('day_of_week' not in database):\n",
    "        \n",
    "        database['day_of_week'] = database['activation_date'].apply(lambda x: np.int32(x.dayofweek))\n",
    "        \n",
    "        \n",
    "def extract_jpg_from_zipfileobject(zip_obj,jpg_id, verbose = False):\n",
    "    \"\"\"\n",
    "    Extracts jpg identified by jpg_id to disk. Returns full path of saved file.\n",
    "    \n",
    "    zip_obj: Zipfile object corresponding to appropriate zip archive\n",
    "    \n",
    "    jpg_id: jpg ID as saved in competition CSV under \"image\" fieldname\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    loaded_file = None\n",
    "\n",
    "    if (isinstance(jpg_id,np.float)):\n",
    "        if (verbose):\n",
    "            print(\"Passed jpg_id is not a string.\")\n",
    "        return loaded_file\n",
    "    \n",
    "    if (zip_obj.filename.find('train') != -1):\n",
    "        file = r'data/competition_files/train_jpg/' + jpg_id + '.jpg'\n",
    "    else:\n",
    "        file = r'data/competition_files/test_jpg/' + jpg_id + '.jpg'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        if (verbose):\n",
    "            print(\"Attempting to extract {:s}...\".format(file))\n",
    "\n",
    "        loaded_file = zip_obj.extract(file,path = os.path.split(os.getcwd())[0])\n",
    "\n",
    "        if (verbose):\n",
    "            print(\"Successfully extracted {:s}.\".format(loaded_file))\n",
    "\n",
    "    except Exception as e:\n",
    "        if (verbose):\n",
    "            print(\"Extraction failed.\")\n",
    "        print(e)\n",
    "\n",
    "    return loaded_file\n",
    "\n",
    "\n",
    "def add_1way_meanencodings(database,categorical_vars_to_encode,\\\n",
    "    tr_val_log_dict,mean_fill_flag = True):\n",
    "    \"\"\"\n",
    "    Mean target ('deal_probability') encodes fields in categorical_vars_to_encode.\n",
    "    \n",
    "    database: net_CSV\n",
    "    \n",
    "    categorical_vars_to_encode: list of fieldnames in database to mean encode\n",
    "    \n",
    "    mean_fill_flag: if True, fills in values not represented in mean encoding training set\n",
    "    with mean of \n",
    "    \"\"\"\n",
    "    \n",
    "    target_fieldname = 'deal_probability'\n",
    "    \n",
    "    #Perform CV only with training set to generate mean encodings for training set.\n",
    "    #Use entire training set to perform mean encoding for validation set plus test set.\n",
    "\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits = n_splits,shuffle = True,random_state = 0)\n",
    "\n",
    "    database_train_indices = database.index[tr_val_log_dict['training_logical']]\n",
    "\n",
    "    database_val_plus_test_indices = \\\n",
    "    database.index[np.logical_or(\\\n",
    "    tr_val_log_dict['validation_logical'],\\\n",
    "    tr_val_log_dict['test_logical'])]\n",
    "\n",
    "    #initializing mean encoding columns\n",
    "    for categorical_var_to_encode in categorical_vars_to_encode:\n",
    "\n",
    "        crnt_ME_name = 'ME_' + categorical_var_to_encode\n",
    "\n",
    "        database[crnt_ME_name] = np.float32(0)\n",
    "\n",
    "    #generating mean encoding for training set\n",
    "    with tqdm(total = n_splits) as tq:\n",
    "\n",
    "        for tr_ind,OOF_ind in kf.split(database_train_indices,database_train_indices):\n",
    "\n",
    "            for categorical_var_to_encode in categorical_vars_to_encode:\n",
    "\n",
    "                crnt_ME_name = 'ME_' + categorical_var_to_encode\n",
    "\n",
    "                #ME_gb is a Series object with indices equal to the unique\n",
    "                #categories of database.loc[database_train_indices[tr_ind],categorical_var_to_encode] \n",
    "                #and values equal to the means within\n",
    "                #the aforementioned categories of\n",
    "                #database.loc[database_train_indices[tr_ind],target_fieldname]. \n",
    "                ME_gb = database.loc[database_train_indices[tr_ind],:].groupby(\\\n",
    "                [categorical_var_to_encode])[target_fieldname].agg(np.mean)\n",
    "\n",
    "                ME_gb_mean = np.mean(ME_gb.values.astype(np.float32))\n",
    "\n",
    "                if mean_fill_flag:\n",
    "                    fill_value = ME_gb_mean\n",
    "                else:\n",
    "                    fill_value = np.nan\n",
    "\n",
    "                #This call of the map method maps the categories of  \n",
    "                #database.loc[database_train_indices[OOF_ind],categorical_var_to_encode] to\n",
    "                #the mean values within those catgeories \n",
    "                #of database.loc[database_train_indices[tr_ind],target_fieldname] \n",
    "                database.loc[database_train_indices[OOF_ind],crnt_ME_name] = \\\n",
    "                database.loc[database_train_indices[OOF_ind],categorical_var_to_encode].map(ME_gb)\n",
    "\n",
    "                database.loc[database_train_indices[OOF_ind],crnt_ME_name] = \\\n",
    "                database.loc[database_train_indices[OOF_ind],crnt_ME_name].fillna(value = fill_value,axis = 0)\n",
    "\n",
    "            tq.update(1)\n",
    "\n",
    "    #generating mean encoding for validation and test set using entire\n",
    "    #training set\n",
    "    for categorical_var_to_encode in categorical_vars_to_encode:\n",
    "\n",
    "        crnt_ME_name = 'ME_' + categorical_var_to_encode\n",
    "\n",
    "        ME_gb = database.loc[database_train_indices,:].groupby(\\\n",
    "        [categorical_var_to_encode])[target_fieldname].agg(np.mean)\n",
    "\n",
    "        ME_gb_mean = np.mean(ME_gb.values.astype(np.float32))\n",
    "\n",
    "        if mean_fill_flag:\n",
    "            fill_value = ME_gb_mean\n",
    "        else:\n",
    "            fill_value = np.nan\n",
    "\n",
    "        database.loc[database_val_plus_test_indices,crnt_ME_name] = \\\n",
    "        database.loc[database_val_plus_test_indices,categorical_var_to_encode].map(ME_gb)\n",
    "\n",
    "        database.loc[database_val_plus_test_indices,crnt_ME_name] = \\\n",
    "        database.loc[database_val_plus_test_indices,crnt_ME_name].fillna(value = fill_value,axis = 0)\n",
    "\n",
    "    if mean_fill_flag:\n",
    "\n",
    "        for categorical_var_to_encode in categorical_vars_to_encode:\n",
    "        \n",
    "            crnt_ME_name = 'ME_' + categorical_var_to_encode\n",
    "\n",
    "            assert(not(\\\n",
    "            database.loc[:,crnt_ME_name].isna().any().any())),print(database.loc[:,crnt_ME_name].isna())\n",
    "\n",
    "    print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences_from__processed_strings(database,column_to_tokenize,tokenizer,indices,maxlen):\n",
    "    \"\"\"\n",
    "    Applies trained tokenizer to convert list of processed descriptions to list of\n",
    "    padded index sequences, which is returned (database is not modified).\n",
    "    \n",
    "    database: database with fieldname of value of column_to_tokenize\n",
    "    \n",
    "    column_to_tokenize: fieldname to tokenize\n",
    "    \n",
    "    tokenizer: trained instance of keras tokenizer\n",
    "    \n",
    "    indices: array of indices into database indicating which records are to be processed \n",
    "    \n",
    "    max_len: maximum sequence length; sequences less than this length will be pre-padded with 0s \n",
    "    \"\"\"\n",
    "    \n",
    "    assert(column_to_tokenize in database.columns)\n",
    "    \n",
    "    texts = list(database.loc[indices,column_to_tokenize])\n",
    "    \n",
    "    texts = enforce_list_elements_to_str(texts)\n",
    "    \n",
    "    sequences = return_tokenized_sequences(tokenizer,texts)\n",
    "    \n",
    "    #for sequences less than maxlen, pad at the beginning of the sequence to fill it\n",
    "    #out to maxlen\n",
    "    padding = 'pre'\n",
    "    \n",
    "    #remove values from sequences larger than maxlen at the end of the sequences,\n",
    "    #the rationale being that tokens at the beginning of the sequence are more\n",
    "    #meaningful to the target and should therefore be retained\n",
    "    truncating = 'post'\n",
    "    \n",
    "    padded_sequences = pad_sequences(sequences, maxlen=maxlen, \\\n",
    "    padding=padding, truncating=truncating)\n",
    "        \n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "def return_single_features(database,column_name,training_mean,training_sd,idxs,mean_fill_flag = False):\n",
    "    \"\"\"\n",
    "    Returns normalized features from competition CSV for field \n",
    "    with name of value of column_name.\n",
    "    \n",
    "    \"\"\"\n",
    "    val_array = database.loc[idxs,column_name].values.astype(np.float32)\n",
    "    val_does_not_exist = database.loc[idxs,column_name].isna().values\n",
    "    \n",
    "    if (mean_fill_flag):\n",
    "        #set values that do not exist to training mean (were nan)\n",
    "        val_array[val_does_not_exist] = training_mean\n",
    "\n",
    "    #normalize feature using training mean and sd\n",
    "    val_array -= training_mean\n",
    "    val_array /= training_sd\n",
    "\n",
    "    if (not(mean_fill_flag)):\n",
    "        #set values that do not exist to 0 (were nan)\n",
    "        val_array[val_does_not_exist] = 0.\n",
    "\n",
    "    val_does_not_exist = val_does_not_exist.astype(np.float32)\n",
    "    \n",
    "    return val_array,val_does_not_exist\n",
    "\n",
    "\n",
    "def return_feature_normalization_parameters(database,tr_val_log_dict,column_name,verbose = False):\n",
    "    \"\"\"\n",
    "    Returns mean and sd for columns restricted to training indices for field in\n",
    "    competition CSV with name of value of column_name.\n",
    "    \"\"\"\n",
    "    \n",
    "    training_indices = np.where(tr_val_log_dict['training_logical'])[0]\n",
    "    \n",
    "    val_training_array = database.loc[training_indices,column_name].values\n",
    "    \n",
    "    val_isnotnan = \\\n",
    "    np.where(np.logical_not(database.loc[training_indices,column_name].isna().values))[0]\n",
    "    \n",
    "    val_training_mean = \\\n",
    "    val_training_array[val_isnotnan].mean()\n",
    "    \n",
    "    val_training_sd = \\\n",
    "    val_training_array[val_isnotnan].std()\n",
    "    \n",
    "    if (verbose):\n",
    "        print(\"for feature '{:s}':\\nmean = {:.4f}, sd = {:.4f}, % nan = {:.2f}%\".format(\\\n",
    "        column_name,val_training_mean,val_training_sd,\\\n",
    "        100*(training_indices.shape[0] - val_isnotnan.shape[0])/training_indices.shape[0]))\n",
    "    \n",
    "    return val_training_mean,val_training_sd\n",
    "\n",
    "\n",
    "def return_summarizer_for_scalar_feature_NA(database,scalar_feature_name_list,\\\n",
    "    tr_val_log_dict,verbose = False,s_retention_thresh = 1E-6):\n",
    "    \"\"\"\n",
    "    Returns a k x k' (k' <= k) summarizer_matrix that when \n",
    "    pre-multiplied by an n X k matrix A of value NA indicators\n",
    "    (corresponding to the fieldnames in the order as they\n",
    "    are represented in scalar_feature_name_list) \n",
    "    yields an n x k' linear transformation of A that is \n",
    "    orthogonal to singular vectors of A\n",
    "    whose singular values are less than s_retention_thresh. \n",
    "    Only training records are used to compute the summarizer_matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    training_indices = database.index[tr_val_log_dict['training_logical']]\n",
    "    \n",
    "    value_NA_list = []\n",
    "    \n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "\n",
    "        val_does_not_exist = \\\n",
    "        database.loc[training_indices,scalar_feature_name].isna().values.astype(np.float32).reshape(-1,1)\n",
    "\n",
    "        value_NA_list.append(val_does_not_exist)\n",
    "        \n",
    "    value_NA_array = np.concatenate(value_NA_list,axis = 1)\n",
    "\n",
    "    U,s,V_T = np.linalg.svd(value_NA_array,full_matrices = False,compute_uv = True)\n",
    "    \n",
    "    num_original_features = value_NA_array.shape[1]\n",
    "    \n",
    "    indices_to_retain = np.where(s > s_retention_thresh)[0]\n",
    "    \n",
    "    summarizer_matrix = np.matmul(V_T.T[:,indices_to_retain],np.diag(1/s[indices_to_retain]))\n",
    "    \n",
    "    dim_summarized = summarizer_matrix.shape[1]\n",
    "    \n",
    "    summarized_training_NA_array = np.matmul(value_NA_array,summarizer_matrix)\n",
    "    \n",
    "    summary_NA_features_mean = np.mean(summarized_training_NA_array,axis = 0) \n",
    "    summary_NA_features_sd = np.std(summarized_training_NA_array,axis = 0) \n",
    "    \n",
    "    if (verbose):\n",
    "        print(\"# of NA indicators = {:d}\".format(NA_indicator_array.shape[1]))\n",
    "        print(\"rank of summarized value existence indicators = {:d}\".format(dim_summarized))\n",
    "    \n",
    "    return summarizer_matrix,dim_summarized,summary_NA_features_mean,summary_NA_features_sd\n",
    "\n",
    "\n",
    "def return_onehot_features_list(database,idxs,one_hot_encoder_dict):\n",
    "    \"\"\"\n",
    "    Returns list of one one-hot arrays for features corresponding to fieldnames_for_one_hot.\n",
    "    Assumes that these features have been tokenized and exist in fields with names\n",
    "    preprended with 'tokenized_'.\n",
    "    \"\"\"\n",
    "            \n",
    "    fieldnames_for_one_hot = ['parent_category_name']\n",
    "\n",
    "    one_hot_features_list = []\n",
    "    \n",
    "    for fieldname_for_onehot in fieldnames_for_one_hot:\n",
    "\n",
    "        crnt_onehot_array = one_hot_encoder_dict[fieldname_for_onehot].transform(\\\n",
    "        database.loc[idxs,'tokenized_' + fieldname_for_onehot].values.reshape(-1,1)).toarray()\n",
    "        \n",
    "        one_hot_features_list.append(crnt_onehot_array)\n",
    "        \n",
    "    return one_hot_features_list\n",
    "    \n",
    "\n",
    "def batch_generator(database,LSTM_tokenizer_dict,one_hot_encoder_dict,\\\n",
    "    scalar_feature_name_list,tr_val_log_dict,use_exists_flag,\\\n",
    "    NA_summarizer_matrix,summary_NA_features_mean,summary_NA_features_sd,\\\n",
    "    batch_size,negative_control_flag = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    database: database corresponding to competition train CSV (\n",
    "    comprising both train and validation records) \n",
    "    \n",
    "    description_tokenizer: keras Tokenizer object trained with training records \n",
    "    of 'description_processed' field of train CSV database\n",
    "    \n",
    "    max_len: maximum number of tokens per string for 'description_processed' field\n",
    "    \n",
    "    tr_val_log_dict: dictionary with keys 'training_logical\" and\n",
    "    'validation_logical' and values of bool arrays that indicates the\n",
    "    training and validation records, respectively.\n",
    "    \n",
    "    exists_summarizer_matrix: a matrix to post-multiply with mini-batch\n",
    "    of value existence indicators for fieldnamess represented in\n",
    "    scalar_feature_name_list; the purpose of this transformation is\n",
    "    to yield (w.r.t. to the net training set, not necessarily every \n",
    "    mini-batch) full-column rank existence features.\n",
    "    \n",
    "    negative_control_flag: if True, then permute indices of target variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    tf.set_random_seed(0)\n",
    "    \n",
    "    training_indices = np.where(tr_val_log_dict['training_logical'])[0]\n",
    "    \n",
    "    num_training_indices = training_indices.shape[0]\n",
    "    \n",
    "    num_batches = np.int(np.ceil(num_training_indices/batch_size))\n",
    "    \n",
    "    scalar_feature_dict_of_dicts = {}\n",
    "    \n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "\n",
    "        crnt_training_mean,crnt_training_sd = \\\n",
    "        return_feature_normalization_parameters(database,tr_val_log_dict,column_name = scalar_feature_name,\\\n",
    "        verbose = True)\n",
    "        \n",
    "        crnt_feature_dict = {}\n",
    "        \n",
    "        crnt_feature_dict['training_mean'] = crnt_training_mean\n",
    "        \n",
    "        crnt_feature_dict['training_sd'] = crnt_training_sd\n",
    "        \n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name] = crnt_feature_dict\n",
    "            \n",
    "    while (True):\n",
    "    \n",
    "        rand_idxs = np.random.permutation(num_training_indices)\n",
    "\n",
    "        #looping over mini-batches\n",
    "        for batch_num in range(num_batches):\n",
    "\n",
    "            start_idx = batch_num*batch_size\n",
    "\n",
    "            end_idx = min((batch_num + 1)*batch_size,num_training_indices)\n",
    "\n",
    "            #current_idxs are the record indices into database that represent\n",
    "            #the current batch. Note that current_idxs are a subset of training_indices.\n",
    "            current_idxs = training_indices[rand_idxs[start_idx:end_idx]]\n",
    "\n",
    "            #allocating arrays for current batch\n",
    "\n",
    "            #features\n",
    "            crnt_batch_size = len(current_idxs)\n",
    "\n",
    "            #crnt_input_array = np.zeros((crnt_batch_size,) + model_image_input_shape + (1,),dtype = np.float32)\n",
    "            \n",
    "            description_sequences_array = \\\n",
    "            generate_sequences_from__processed_strings(\\\n",
    "            database,'description_processed',\\\n",
    "            LSTM_tokenizer_dict['description_processed'],current_idxs,\\\n",
    "            DESCRIPTION_MAX_LEN)\n",
    "            \n",
    "            title_sequences_array = \\\n",
    "            generate_sequences_from__processed_strings(\\\n",
    "            database,'title_processed',\\\n",
    "            LSTM_tokenizer_dict['title_processed'],current_idxs,\\\n",
    "            TITLE_MAX_LEN)\n",
    "            \n",
    "            object_classification_vector_array = \\\n",
    "            np.vstack(load_object_classification_vectors(list(database.loc[current_idxs,'image'])))\n",
    "            \n",
    "            for scalar_feature_name in scalar_feature_name_list:\n",
    "                \n",
    "                crnt_array,crnt_exists = \\\n",
    "                return_single_features(database,scalar_feature_name,\\\n",
    "                scalar_feature_dict_of_dicts[scalar_feature_name]['training_mean'],\\\n",
    "                scalar_feature_dict_of_dicts[scalar_feature_name]['training_sd'],\\\n",
    "                current_idxs,\\\n",
    "                mean_fill_flag = True)\n",
    "                \n",
    "                scalar_feature_dict_of_dicts[scalar_feature_name]['array'] = crnt_array\n",
    "                scalar_feature_dict_of_dicts[scalar_feature_name]['NA'] = crnt_exists\n",
    "                        \n",
    "            one_hot_features_list = return_onehot_features_list(database,current_idxs,one_hot_encoder_dict)\n",
    "            \n",
    "            #add more features here as desired\n",
    "            crnt_feature_list = [description_sequences_array,title_sequences_array,object_classification_vector_array]\n",
    "            \n",
    "            NA_features_list = []\n",
    "            \n",
    "            for scalar_feature_name in scalar_feature_name_list:\n",
    "                \n",
    "                crnt_feature_list.append(scalar_feature_dict_of_dicts[scalar_feature_name]['array'])\n",
    "                \n",
    "                NA_features_list.append(scalar_feature_dict_of_dicts[scalar_feature_name]['NA'].reshape(-1,1))\n",
    "                \n",
    "            if (use_exists_flag):\n",
    "\n",
    "                NA_features_array = np.concatenate(NA_features_list,axis = 1)\n",
    "                \n",
    "                summarized_NA_features_array = np.matmul(NA_features_array,NA_summarizer_matrix)\n",
    "                \n",
    "                summarized_NA_features_array -= summary_NA_features_mean\n",
    "                summarized_NA_features_array /= summary_NA_features_sd\n",
    "\n",
    "                crnt_feature_list += \\\n",
    "                np.split(summarized_NA_features_array,\\\n",
    "                NA_summarizer_matrix.shape[1],\\\n",
    "                axis = 1)\n",
    "\n",
    "            #crnt_feature_list += one_hot_features_list\n",
    "            \n",
    "            if (negative_control_flag):\n",
    "\n",
    "                target_idxs = np.random.permutation(current_idxs)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                target_idxs = current_idxs\n",
    "                \n",
    "            crnt_target_array = database.loc[target_idxs,'deal_probability']\n",
    " \n",
    "            yield (crnt_feature_list,crnt_target_array)\n",
    "\n",
    "    \n",
    "def generate_validation_tuple(database,tr_val_log_dict,use_exists_flag,\\\n",
    "    NA_summarizer_matrix,summary_NA_features_mean,summary_NA_features_sd,LSTM_tokenizer_dict,\\\n",
    "    one_hot_encoder_dict,scalar_feature_name_list,dataset_mode):\n",
    "    \n",
    "    scalar_feature_dict_of_dicts = {}\n",
    "    \n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "\n",
    "        crnt_training_mean,crnt_training_sd = \\\n",
    "        return_feature_normalization_parameters(database,tr_val_log_dict,column_name = scalar_feature_name,\\\n",
    "        verbose = False)\n",
    "        \n",
    "        crnt_feature_dict = {}\n",
    "        \n",
    "        crnt_feature_dict['training_mean'] = crnt_training_mean\n",
    "        \n",
    "        crnt_feature_dict['training_sd'] = crnt_training_sd\n",
    "        \n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name] = crnt_feature_dict\n",
    "        \n",
    "    if (dataset_mode == 'validation'):\n",
    "        database_indices = np.where(tr_val_log_dict['validation_logical'])[0]\n",
    "    elif (dataset_mode == 'test'):\n",
    "        database_indices = np.where(tr_val_log_dict['test_logical'])[0]\n",
    "    else:\n",
    "        assert(False),print(\"Unexpected value of dataset_mode: \",dataset_mode)\n",
    "        \n",
    "    description_sequences_array = \\\n",
    "    generate_sequences_from__processed_strings(\\\n",
    "    database,'description_processed',\\\n",
    "    LSTM_tokenizer_dict['description_processed'],database_indices,\\\n",
    "    DESCRIPTION_MAX_LEN)\n",
    "    \n",
    "    title_sequences_array = \\\n",
    "    generate_sequences_from__processed_strings(\\\n",
    "    database,'title_processed',\\\n",
    "    LSTM_tokenizer_dict['title_processed'],database_indices,\\\n",
    "    TITLE_MAX_LEN)\n",
    "    \n",
    "    object_classification_vector_array = \\\n",
    "    np.vstack(load_object_classification_vectors(list(database.loc[database_indices,'image'])))\n",
    "    \n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "                \n",
    "        crnt_array,crnt_exists = \\\n",
    "        return_single_features(database,scalar_feature_name,\\\n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name]['training_mean'],\\\n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name]['training_sd'],\\\n",
    "        database_indices,\\\n",
    "        mean_fill_flag = True)\n",
    "\n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name]['array'] = crnt_array\n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name]['NA'] = crnt_exists\n",
    "\n",
    "    one_hot_features_list = \\\n",
    "    return_onehot_features_list(database,database_indices,one_hot_encoder_dict)\n",
    "    \n",
    "    #add more features here as desired\n",
    "    crnt_feature_list = [description_sequences_array,title_sequences_array,object_classification_vector_array]\n",
    "        \n",
    "    NA_features_list = []\n",
    "    \n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "                \n",
    "        crnt_feature_list.append(scalar_feature_dict_of_dicts[scalar_feature_name]['array'])\n",
    "                \n",
    "        NA_features_list.append(\\\n",
    "        scalar_feature_dict_of_dicts[scalar_feature_name]['NA'].reshape(-1,1))\n",
    "      \n",
    "    if (use_exists_flag):\n",
    "        \n",
    "        NA_features_array = np.concatenate(NA_features_list,axis = 1)\n",
    "\n",
    "        summarized_NA_features_array = np.matmul(NA_features_array,NA_summarizer_matrix)\n",
    "        \n",
    "        summarized_NA_features_array -= summary_NA_features_mean\n",
    "        summarized_NA_features_array /= summary_NA_features_sd\n",
    "\n",
    "        crnt_feature_list += \\\n",
    "        np.split(summarized_NA_features_array,\\\n",
    "        NA_summarizer_matrix.shape[1],\\\n",
    "        axis = 1)\n",
    "\n",
    "    if (dataset_mode == 'test'):\n",
    "        \n",
    "        return crnt_feature_list\n",
    "        \n",
    "    #crnt_feature_list += one_hot_features_list\n",
    "            \n",
    "    crnt_target_array = database.loc[database_indices,'deal_probability']\n",
    "\n",
    "    return (crnt_feature_list,crnt_target_array)\n",
    "\n",
    "\n",
    "def deep_dense(input_layer,dense_units_list,activation_list):\n",
    "    \"\"\"\n",
    "    Creates a chain of dense layers with batch normalization.\n",
    "    \n",
    "    input_layer: output of a keras layer, will be used as the input to first dense layer in chain\n",
    "    \n",
    "    dense_units_list: a list of the number of units per dense layer in chain  \n",
    "    \n",
    "    activation_list: a list of the activation functions (as strings) per dense layer in chain\n",
    "    \"\"\"\n",
    "    \n",
    "    Dense_layer_list = []\n",
    "    Batch_layer_list = []\n",
    "    Activation_layer_list = []\n",
    "    \n",
    "    num_dense_layers = len(dense_units_list)\n",
    "    \n",
    "    print(\"len dense_units_list = {:d}\".format(num_dense_layers))\n",
    "    print(\"len activation_list = {:d}\".format(len(activation_list)))\n",
    "    \n",
    "    assert(num_dense_layers == len(activation_list))\n",
    "    \n",
    "    for layer_idx in range(num_dense_layers):\n",
    "        \n",
    "        Dense_layer_list.append(\\\n",
    "        L.Dense(units = dense_units_list[layer_idx], \\\n",
    "        activation = None,use_bias = False, name = 'dense_chain_Dense_layer_' + str(layer_idx)))\n",
    "            \n",
    "        if (activation_list[layer_idx] == 'relu' or activation_list[layer_idx] == 'linear'):\n",
    "            scale = False\n",
    "        else:\n",
    "            scale = True\n",
    "            \n",
    "        Batch_layer_list.append(\\\n",
    "        L.BatchNormalization(axis = -1, center=True, scale = scale,\\\n",
    "        name = 'dense_chain_Batchnorm_layer_' + str(layer_idx)))\n",
    "        \n",
    "        Activation_layer_list.append(\\\n",
    "        L.Activation(activation=activation_list[layer_idx],\\\n",
    "        name = 'dense_chain_Activation_layer_' + str(layer_idx)))\n",
    "        \n",
    "    #memory[0]: 1-back\n",
    "    #memory[1]: 2-back\n",
    "    memory = [None,None]\n",
    "    \n",
    "    last_output = input_layer\n",
    "\n",
    "    for layer_idx in range(num_dense_layers):\n",
    "\n",
    "        B = Batch_layer_list[layer_idx]\n",
    "\n",
    "        D = Dense_layer_list[layer_idx]\n",
    "        \n",
    "        A = Activation_layer_list[layer_idx]\n",
    "\n",
    "        #reshape back to rank 4 (batch size,rows,cols,channels)\n",
    "        last_output = D(last_output)\n",
    "        \n",
    "        #batch normalization\n",
    "        last_output = B(last_output)\n",
    "\n",
    "        #residual\n",
    "        if (memory[1] is not None):\n",
    "\n",
    "            crnt2back = memory[1]\n",
    "            \n",
    "            if (K.int_shape(crnt2back)[1] != K.int_shape(last_output)[1]):\n",
    "                \n",
    "                crnt2back = \\\n",
    "                L.Dense(units = K.int_shape(last_output)[1],activation = None,use_bias = False,\\\n",
    "                name = 'ResizeDense_layer_' + str(layer_idx - 2) + '_to_' +  str(layer_idx))(crnt2back)\n",
    "            \n",
    "            last_output = L.Add()([last_output,crnt2back])\n",
    "\n",
    "        last_output = A(last_output)\n",
    "        \n",
    "        memory[1] = memory[0]\n",
    "        memory[0] = last_output\n",
    "        \n",
    "    return last_output\n",
    "\n",
    "\n",
    "def define_model(embedding_layers_dict, LSTM_dim, \\\n",
    "    scalar_feature_name_list,\\\n",
    "    LSTM_dropout_flag = False,LSTM_dropout_rate = 0.0,\\\n",
    "    reduce_wordvec_dim_flag = False,stacked_LSTM_flag = False,\\\n",
    "    object_classification_flag = False):\n",
    "    \"\"\"\n",
    "    Creates keras model graph.\n",
    "    \n",
    "    Arguments:\n",
    "    embedding_layers_dict: dictionary of keras embedding layers with pretrained weights and set to non-trainable. \n",
    "    \n",
    "    descr_max_len: length to use for 'description' sequence padding\n",
    "\n",
    "    LSTM_dim: LSTM state vector dimensionality\n",
    "    \n",
    "    scalar_feature_name_list: a list of names to use to name scalar input layers; the\n",
    "    names are arbitrary, but the list length should match the number of scalar inputs\n",
    "    (including the summarized value existence features)\n",
    "    \n",
    "    LSTM_dropout_flag: if True, places Dropout layers before and after LSTM layers \n",
    "    \n",
    "    LSTM_dropout_rate: used if LSTM_dropout_flag is True\n",
    "    \n",
    "    object_classification_flag: if True, then use object classification vectors\n",
    "    as an input\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    #INPUTS\n",
    "    \n",
    "    #LSTM inputs\n",
    "    description_indices = L.Input(shape = (DESCRIPTION_MAX_LEN,), dtype = np.int32)\n",
    "    \n",
    "    title_indices = L.Input(shape = (TITLE_MAX_LEN,), dtype = np.int32)\n",
    "    \n",
    "    object_classification_vectors = L.Input(shape = (NUM_OBJECT_CLASSES,), dtype = np.float32)\n",
    "    \n",
    "    #scalar inputs\n",
    "    scalar_feature_input_layer_list = []\n",
    "    for scalar_feature_name in scalar_feature_name_list:\n",
    "        \n",
    "        scalar_feature_input_layer_list.append(L.Input(shape = (1,), \\\n",
    "        dtype = np.float32,name = scalar_feature_name))\n",
    "        \n",
    "    #discarded variables:\n",
    "    #description_processed_length\n",
    "    \n",
    "    #one-hot inputs\n",
    "    #parent_category_onehot = L.Input(shape = (10,), dtype = np.float32,name = 'parent_category_onehot')\n",
    "    \n",
    "    description_embeddings = embedding_layers_dict['description_processed'](description_indices)\n",
    "\n",
    "    title_embeddings = embedding_layers_dict['title_processed'](title_indices)\n",
    "    \n",
    "    if (LSTM_dropout_flag):\n",
    "        \n",
    "        description_embeddings = L.Dropout(rate = LSTM_dropout_rate)(description_embeddings)\n",
    "        \n",
    "        title_embeddings = L.Dropout(rate = LSTM_dropout_rate)(title_embeddings)\n",
    "    \n",
    "    if (stacked_LSTM_flag):\n",
    "\n",
    "        X_description = L.LSTM(units = LSTM_dim,return_sequences = True)(description_embeddings)\n",
    "        # Add dropout with a probability of 0.5\n",
    "        #X_description = L.Dropout(rate = 0.5)(X_description)\n",
    "        X_description = L.LSTM(units = LSTM_dim,return_sequences = False)(X_description)\n",
    "        \n",
    "        X_title = L.LSTM(units = LSTM_dim,return_sequences = True)(title_embeddings)\n",
    "        # Add dropout with a probability of 0.5\n",
    "        #X_title = L.Dropout(rate = 0.5)(X_title)\n",
    "        X_title = L.LSTM(units = LSTM_dim,return_sequences = False)(X_title)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if (reduce_wordvec_dim_flag):\n",
    "        \n",
    "            reduced_dim_description_embeddings = \\\n",
    "            L.Dense(units = 50, activation= None,name = 'reduced_dim_description_embeddings')(description_embeddings)\n",
    "\n",
    "            reduced_dim_title_embeddings = \\\n",
    "            L.Dense(units = 50, activation= None,name = 'reduced_dim_title_embeddings')(title_embeddings)\n",
    "\n",
    "            X_description = L.LSTM(units = \\\n",
    "            LSTM_dim,return_sequences = False,name = 'description_LSTM')(reduced_dim_description_embeddings)\n",
    "\n",
    "            X_title = L.LSTM(units = LSTM_dim,return_sequences = False,name = 'title_LSTM')(reduced_dim_title_embeddings)\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            X_description = L.LSTM(\\\n",
    "            units = LSTM_dim,return_sequences = False,name = 'description_LSTM')(description_embeddings)\n",
    "\n",
    "            X_title = L.LSTM(\\\n",
    "            units = LSTM_dim,return_sequences = False,name = 'title_LSTM')(title_embeddings)\n",
    "            \n",
    "        if (LSTM_dropout_flag):\n",
    "\n",
    "            X_description = L.Dropout(rate = LSTM_dropout_rate,name = 'X_description')(X_description)\n",
    "\n",
    "            X_title = L.Dropout(rate = LSTM_dropout_rate,name = 'X_title')(X_title)\n",
    "\n",
    "    # Add dropout with a probability of 0.5\n",
    "    #X = Dropout(rate = 0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    \n",
    "    #concatenation layer\n",
    "    \n",
    "    concat = L.Concatenate(axis = -1)\n",
    "\n",
    "    features_list = [X_description,X_title]\n",
    "    \n",
    "    if (object_classification_flag):\n",
    "        \n",
    "        reduced_dim_object_classification_vectors = \\\n",
    "        L.Dense(200,activation= 'relu',name = 'reduced_dim_object_classification_vectors')(object_classification_vectors)\n",
    "        \n",
    "        features_list.append(reduced_dim_object_classification_vectors)\n",
    "    \n",
    "    features_list += scalar_feature_input_layer_list\n",
    "    #+ [parent_category_onehot]\n",
    "\n",
    "    X = concat(features_list)\n",
    "    \n",
    "    #X = L.Dense(units = 20, activation='relu')(X)\n",
    "    #X = L.Dense(units = 1, activation='sigmoid')(X)\n",
    "    X = deep_dense(X,\\\n",
    "    dense_units_list = [20,10,1],\\\n",
    "    activation_list = ['relu']*2 + ['sigmoid'])\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    if (object_classification_flag):\n",
    "        \n",
    "        model = Model(inputs = \\\n",
    "        [description_indices,title_indices,object_classification_vectors] \\\n",
    "        + scalar_feature_input_layer_list,\\\n",
    "        outputs = X)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model = Model(inputs = \\\n",
    "        [description_indices,title_indices] \\\n",
    "        + scalar_feature_input_layer_list,\\\n",
    "        outputs = X)\n",
    "    \n",
    "    #+ [parent_category_onehot], \\\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model    \n",
    "\n",
    "\n",
    "#LOSS\n",
    "def Avito_loss(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_net.csv...\n",
      "loaded net_CSV\n",
      "# training records = 1275576\n",
      "# validation records = 227848\n",
      "# test records = 508438\n",
      "total # records in net_CSV = 2011862\n",
      "% of total train CSV records comprising validation = 15.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f792f4cfea347dabe7d0f778d213a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent_category_name\n",
      "total # of empty tokens found = 0\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "category_name\n",
      "total # of empty tokens found = 0\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "param_1\n",
      "total # of empty tokens found = 0\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "param_2\n",
      "total # of empty tokens found = 10\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "param_1\n",
      "total # of empty tokens found = 0\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "param_3\n",
      "total # of empty tokens found = 127\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "user_type\n",
      "total # of empty tokens found = 0\n",
      "total # of empty tokens found = 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "if True:\n",
    "    #load everything\n",
    "    #train_CSV,test_CSV,tr_val_log_dict,word_to_glove_vec,\\\n",
    "    #LSTM_tokenizer_dict,embedding_layers_dict,tokenizer_dict,one_hot_encoder_dict = \\\n",
    "    #start_up(train_CSV_flag = True, load_CSV_only_flag = False)\n",
    "\n",
    "    net_CSV,tr_val_log_dict,word_to_glove_vec,\\\n",
    "    LSTM_tokenizer_dict,embedding_layers_dict,tokenizer_dict,one_hot_encoder_dict =\\\n",
    "    start_up(load_CSV_only_flag = False,\\\n",
    "    word_to_glove_vec = None,embedding_layers_dict = None)\n",
    "    \n",
    "else:\n",
    "    #just load CSV\n",
    "    net_CSV = start_up(load_CSV_only_flag = True)\n",
    "\n",
    "    \n",
    "    #train_CSV = \\\n",
    "    #start_up(train_CSV_flag = True,load_CSV_only_flag = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ALL ABOVE FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_feature_name_list = ['price','image_top_1','NIMA_mean','ME_city','ME_parent_category_name',\\\n",
    "'ME_category_name','ME_item_seq_number','ME_user_type','ME_day_of_week',\\\n",
    "'ME_param_1','ME_param_2','ME_param_3']\n",
    "\n",
    "use_exists_flag = True\n",
    "\n",
    "NA_summarizer_matrix,rank_NA_summarizer_matrix,\\\n",
    "summary_NA_features_mean,summary_NA_features_sd = \\\n",
    "return_summarizer_for_scalar_feature_NA(net_CSV,\\\n",
    "scalar_feature_name_list,tr_val_log_dict,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dense_units_list = 3\n",
      "len activation_list = 3\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "if (use_exists_flag):\n",
    "    augmented_scalar_feature_name_list = list(scalar_feature_name_list)\n",
    "    for idx in range(rank_NA_summarizer_matrix):\n",
    "        augmented_scalar_feature_name_list += ['scalar_NA_feature_' + str(idx)]\n",
    "    \n",
    "model = define_model(embedding_layers_dict, LSTM_dim = 64, \\\n",
    "scalar_feature_name_list = augmented_scalar_feature_name_list,\\\n",
    "LSTM_dropout_flag = True,LSTM_dropout_rate = 0.25,reduce_wordvec_dim_flag = False,\\\n",
    "object_classification_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      194269500   input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10, 300)      59938500    input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 50, 300)      0           embedding_1[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 10, 300)      0           embedding_2[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "description_LSTM (LSTM)         (None, 64)           93440       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "title_LSTM (LSTM)               (None, 64)           93440       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X_description (Dropout)         (None, 64)           0           description_LSTM[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "X_title (Dropout)               (None, 64)           0           title_LSTM[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reduced_dim_object_classificati (None, 200)          200200      input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "price (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_top_1 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NIMA_mean (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_city (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_parent_category_name (InputL (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_category_name (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_item_seq_number (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_user_type (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_day_of_week (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_param_1 (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_param_2 (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ME_param_3 (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_0 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_1 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_2 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_3 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_4 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "scalar_NA_feature_5 (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 346)          0           X_description[0][0]              \n",
      "                                                                 X_title[0][0]                    \n",
      "                                                                 reduced_dim_object_classification\n",
      "                                                                 price[0][0]                      \n",
      "                                                                 image_top_1[0][0]                \n",
      "                                                                 NIMA_mean[0][0]                  \n",
      "                                                                 ME_city[0][0]                    \n",
      "                                                                 ME_parent_category_name[0][0]    \n",
      "                                                                 ME_category_name[0][0]           \n",
      "                                                                 ME_item_seq_number[0][0]         \n",
      "                                                                 ME_user_type[0][0]               \n",
      "                                                                 ME_day_of_week[0][0]             \n",
      "                                                                 ME_param_1[0][0]                 \n",
      "                                                                 ME_param_2[0][0]                 \n",
      "                                                                 ME_param_3[0][0]                 \n",
      "                                                                 scalar_NA_feature_0[0][0]        \n",
      "                                                                 scalar_NA_feature_1[0][0]        \n",
      "                                                                 scalar_NA_feature_2[0][0]        \n",
      "                                                                 scalar_NA_feature_3[0][0]        \n",
      "                                                                 scalar_NA_feature_4[0][0]        \n",
      "                                                                 scalar_NA_feature_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Dense_layer_0 (Dens (None, 20)           6920        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Batchnorm_layer_0 ( (None, 20)           60          dense_chain_Dense_layer_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Activation_layer_0  (None, 20)           0           dense_chain_Batchnorm_layer_0[0][\n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Dense_layer_1 (Dens (None, 10)           200         dense_chain_Activation_layer_0[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Batchnorm_layer_1 ( (None, 10)           30          dense_chain_Dense_layer_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Activation_layer_1  (None, 10)           0           dense_chain_Batchnorm_layer_1[0][\n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Dense_layer_2 (Dens (None, 1)            10          dense_chain_Activation_layer_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Batchnorm_layer_2 ( (None, 1)            4           dense_chain_Dense_layer_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ResizeDense_layer_0_to_2 (Dense (None, 1)            20          dense_chain_Activation_layer_0[0]\n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1)            0           dense_chain_Batchnorm_layer_2[0][\n",
      "                                                                 ResizeDense_layer_0_to_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_chain_Activation_layer_2  (None, 1)            0           add_11[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 254,602,324\n",
      "Trainable params: 394,262\n",
      "Non-trainable params: 254,208,062\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#COMPILE\n",
    "#lr = 0.001\n",
    "lr = 0.001\n",
    "model.compile(optimizer = K_opt.Adam(lr=0.0001),loss = Avito_loss)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch =  1246\n",
      "Epoch 1/24for feature 'price':\n",
      "mean = 318570.2188, sd = 72579576.0000, % nan = 5.64%\n",
      "\n",
      "for feature 'image_top_1':\n",
      "mean = 1236.4391, sd = 970.9095, % nan = 7.43%\n",
      "for feature 'NIMA_mean':\n",
      "mean = 4.8232, sd = 0.4778, % nan = 7.43%\n",
      "for feature 'ME_city':\n",
      "mean = 0.1394, sd = 0.0193, % nan = 0.00%\n",
      "for feature 'ME_parent_category_name':\n",
      "mean = 0.1394, sd = 0.0795, % nan = 0.00%\n",
      "for feature 'ME_category_name':\n",
      "mean = 0.1394, sd = 0.0912, % nan = 0.00%\n",
      "for feature 'ME_item_seq_number':\n",
      "mean = 0.1394, sd = 0.0385, % nan = 0.00%\n",
      "for feature 'ME_user_type':\n",
      "mean = 0.1394, sd = 0.0207, % nan = 0.00%\n",
      "for feature 'ME_day_of_week':\n",
      "mean = 0.1394, sd = 0.0011, % nan = 0.00%\n",
      "for feature 'ME_param_1':\n",
      "mean = 0.1384, sd = 0.1050, % nan = 4.08%\n",
      "for feature 'ME_param_2':\n",
      "mean = 0.1155, sd = 0.1152, % nan = 43.46%\n",
      "for feature 'ME_param_3':\n",
      "mean = 0.0917, sd = 0.0861, % nan = 57.20%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-901d60c25f86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stoppping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mfit_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m    \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_CSV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLSTM_tokenizer_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_encoder_dict\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mscalar_feature_name_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_val_log_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_exists_flag\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mNA_summarizer_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary_NA_features_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary_NA_features_sd\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnegative_control_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_validation_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_CSV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_val_log_dict\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0muse_exists_flag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNA_summarizer_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary_NA_features_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary_NA_features_sd\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mLSTM_tokenizer_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_encoder_dict\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mscalar_feature_name_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2194\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2196\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#FIT\n",
    "batch_size = 1024\n",
    "num_training_obs = tr_val_log_dict['training_logical'].sum()\n",
    "steps_per_epoch = np.int(np.ceil(num_training_obs/batch_size))\n",
    "num_epochs = 24\n",
    "    \n",
    "print(\"steps_per_epoch = \",steps_per_epoch)\n",
    "\n",
    "early_stoppping = \\\n",
    "EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min')\n",
    "\n",
    "filepath = \\\n",
    "os.path.join(os.getcwd(),'..',os.pathsep,r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\saved_models',\\\n",
    "'model.{epoch:02d}-{val_loss:.4f}.h5')\n",
    "\n",
    "validation_steps = np.int(np.ceil(tr_val_log_dict['validation_logical'].sum()/batch_size))\n",
    "\n",
    "if True:\n",
    "\n",
    "    model_checkpoint = \\\n",
    "    ModelCheckpoint(filepath = filepath, monitor='val_loss', verbose=0, save_best_only=True, \\\n",
    "    save_weights_only=True, mode='min', period=1)\n",
    "\n",
    "    callbacks = [early_stoppping,model_checkpoint]\n",
    "\n",
    "    fit_history = model.fit_generator(\\\n",
    "    generator = batch_generator(net_CSV,LSTM_tokenizer_dict,one_hot_encoder_dict,\\\n",
    "    scalar_feature_name_list,tr_val_log_dict,use_exists_flag,\\\n",
    "    NA_summarizer_matrix,summary_NA_features_mean,summary_NA_features_sd,\\\n",
    "    batch_size,negative_control_flag = False),\\\n",
    "    steps_per_epoch=steps_per_epoch, epochs=num_epochs,\\\n",
    "    verbose=2, callbacks=callbacks,\\\n",
    "    validation_data = generate_validation_tuple(net_CSV,tr_val_log_dict,\\\n",
    "    use_exists_flag,NA_summarizer_matrix,summary_NA_features_mean,summary_NA_features_sd,\\\n",
    "    LSTM_tokenizer_dict,one_hot_encoder_dict,\\\n",
    "    scalar_feature_name_list,dataset_mode = 'validation'),\\\n",
    "    validation_steps = validation_steps)\n",
    "\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_validation_tuple(net_CSV,tr_val_log_dict,\\\n",
    "use_exists_flag,NA_summarizer_matrix,summary_NA_features_mean,summary_NA_features_sd,\\\n",
    "LSTM_tokenizer_dict,one_hot_encoder_dict,\\\n",
    "scalar_feature_name_list,dataset_mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do this without error: run start_up, define model, then load weights here\n",
    "model.load_weights(r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\saved_models\\model.18-0.0502.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_filename = \\\n",
    "os.path.join(os.getcwd(),'..',os.pathsep,r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\predictions',\\\n",
    "'test_predictions.pkl')\n",
    "\n",
    "if False:\n",
    "    with open(test_predictions_filename,mode = 'wb') as test_predictions_fobj:\n",
    "        pickle.dump(test_predictions, test_predictions_fobj)\n",
    "        \n",
    "else:\n",
    "    with open(test_predictions_filename,mode = 'rb') as test_predictions_fobj:\n",
    "        test_predictions = pickle.load(test_predictions_fobj)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_dataframe = \\\n",
    "pd.DataFrame(\\\n",
    "{'item_id': net_CSV.loc[net_CSV['source'] == 'competition test CSV','item_id'],\\\n",
    "'deal_probability': test_predictions.flatten()})\n",
    "\n",
    "test_predictions_dataframe_filename = \\\n",
    "os.path.join(os.getcwd(),'..',os.pathsep,r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\predictions',\\\n",
    "'test_predictions_dataframe.csv')\n",
    "\n",
    "if False:\n",
    "    df = test_predictions_dataframe.iloc[:10]\n",
    "\n",
    "    df.to_csv(test_predictions_dataframe_filename,index = False,\\\n",
    "    columns = ['item_id','deal_probability'])\n",
    "else:\n",
    "    test_predictions_dataframe.to_csv(test_predictions_dataframe_filename,index = False,\\\n",
    "    columns = ['item_id','deal_probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features for lightgbm\n",
    "cols = ['price','image_top_1','NIMA_mean','ME_city','ME_parent_category_name',\\\n",
    "'ME_category_name','ME_item_seq_number','ME_user_type','ME_day_of_week',\\\n",
    "'ME_param_1','ME_param_2','ME_param_3','description_processed_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now on GB with 50 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.233096\n",
      "rmse for validation: 0.230588\n",
      "elapsed time = 0 min 57 s\n",
      "\n",
      "Now on GB with 70 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.230872\n",
      "rmse for validation: 0.228483\n",
      "elapsed time = 1 min 10 s\n",
      "\n",
      "Now on GB with 97 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.229467\n",
      "rmse for validation: 0.227260\n",
      "elapsed time = 1 min 8 s\n",
      "\n",
      "Now on GB with 136 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.228431\n",
      "rmse for validation: 0.226528\n",
      "elapsed time = 1 min 44 s\n",
      "\n",
      "Now on GB with 189 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.227604\n",
      "rmse for validation: 0.226010\n",
      "elapsed time = 2 min 9 s\n",
      "\n",
      "Now on GB with 264 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.226806\n",
      "rmse for validation: 0.225617\n",
      "elapsed time = 2 min 51 s\n",
      "\n",
      "Now on GB with 368 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.225956\n",
      "rmse for validation: 0.225252\n",
      "elapsed time = 3 min 34 s\n",
      "\n",
      "Now on GB with 514 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.224992\n",
      "rmse for validation: 0.224961\n",
      "elapsed time = 5 min 14 s\n",
      "\n",
      "Now on GB with 717 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.223873\n",
      "rmse for validation: 0.224781\n",
      "elapsed time = 6 min 21 s\n",
      "\n",
      "Now on GB with 1000 estimators...\n",
      "fitting on training records...\n",
      "rmse for train: 0.222560\n",
      "rmse for validation: 0.224653\n",
      "elapsed time = 9 min 24 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting for regression\n",
    "\n",
    "min_n_estim = 50\n",
    "max_n_estim = 1000\n",
    "num_steps = 10\n",
    "\n",
    "n_estim_array = \\\n",
    "np.round(np.exp(np.linspace(np.log(min_n_estim),np.log(max_n_estim),num_steps))).astype(np.int32)\n",
    "\n",
    "tr_rmses = np.zeros((len(n_estim_array),))\n",
    "val_rmses = np.zeros((len(n_estim_array),))\n",
    "\n",
    "for idx,n_estim in enumerate(n_estim_array):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"\\nNow on GB with {:d} estimators...\".format(n_estim))\n",
    "\n",
    "    lgbm_params = {\n",
    "                   'feature_fraction': 0.5,\n",
    "                   'metric': 'rmse',\n",
    "                   'nthread':1, \n",
    "                   'min_data_in_leaf': 2**7, \n",
    "                   'bagging_fraction': 0.25, \n",
    "                   'learning_rate': 0.03, \n",
    "                   'objective': 'mse', \n",
    "                   'bagging_seed': 2**7, \n",
    "                   'num_leaves': 2**7,\n",
    "                   'bagging_freq':1,\n",
    "                   'verbose': 0,\n",
    "                   'max_bin': 2**14\n",
    "                  }\n",
    "    \n",
    "    #fitting for validation\n",
    "    print(\"fitting on training records...\")\n",
    "    gbr = lgbm.train(lgbm_params, \\\n",
    "    lgbm.Dataset(net_CSV.loc[tr_val_log_dict['training_logical'],cols], \\\n",
    "    label = net_CSV.loc[tr_val_log_dict['training_logical'],'deal_probability']), n_estim,\\\n",
    "    valid_sets = [lgbm.Dataset(net_CSV.loc[tr_val_log_dict['validation_logical'],cols], \n",
    "    label = net_CSV.loc[tr_val_log_dict['validation_logical'],'deal_probability'])],\\\n",
    "    early_stopping_rounds = None,verbose_eval = False)\n",
    "    \n",
    "    if True:\n",
    "        gbr_pred_tr = gbr.predict(net_CSV.loc[tr_val_log_dict['training_logical'],cols]).astype(np.float16)\n",
    "        gbr_pred_val = gbr.predict(net_CSV.loc[tr_val_log_dict['validation_logical'],cols]).astype(np.float16)\n",
    "        #gbr_pred_test = gbr.predict(net_CSV.loc[tr_val_log_dict['test_logical'],cols]).astype(np.float16)\n",
    "\n",
    "        rmse_tr = \\\n",
    "        np.sqrt(((net_CSV.loc[tr_val_log_dict['training_logical'],'deal_probability'] - \\\n",
    "        gbr_pred_tr)**2).mean())\n",
    "        \n",
    "        rmse_val = \\\n",
    "        np.sqrt(((net_CSV.loc[tr_val_log_dict['validation_logical'],'deal_probability'] - \\\n",
    "        gbr_pred_val)**2).mean())\n",
    "\n",
    "        #pd.Series(gbr_pred_test).to_csv(osp.join(results_path,'gbr_pred_test.csv'))\n",
    "\n",
    "        del gbr_pred_tr,gbr_pred_val\n",
    "        #,gbr_pred_test\n",
    "    \n",
    "        tr_rmses[idx] = rmse_tr\n",
    "        val_rmses[idx] = rmse_val\n",
    "\n",
    "        print(\"rmse for train: {:.6f}\".format(rmse_tr))\n",
    "        print(\"rmse for validation: {:.6f}\".format(rmse_val))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    e_min = np.int(np.floor(elapsed_time/60))\n",
    "    e_sec = np.int(elapsed_time - 60*e_min)\n",
    "    print(\"elapsed time = {:d} min {:d} s\".format(e_min,e_sec))\n",
    "\n",
    "plt.show()\n",
    "plt.xlabel('# estimators')\n",
    "plt.ylabel('rmse')\n",
    "plt.plot(n_estim_array,tr_rmses,'.',color = 'b',label = 'train')\n",
    "plt.plot(n_estim_array,val_rmses,'.',color = 'g',label = 'validation')\n",
    "plt.legend(loc = (1.05,0.5))\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_LGBM(parameters,one_set_params_flag = False):\n",
    "    \n",
    "    if (not(one_set_params_flag)):\n",
    "        \n",
    "        parameters = parameters[0]\n",
    "\n",
    "    lgbm_params = {\\\n",
    "               'feature_fraction': parameters[0],\\\n",
    "               'metric': 'rmse',\\\n",
    "               'nthread':1,\\\n",
    "               'min_data_in_leaf': np.int(parameters[4]),\\\n",
    "               'bagging_fraction': parameters[1],\\\n",
    "               'learning_rate': parameters[2],\\\n",
    "               'objective': 'mse',\\\n",
    "               'bagging_seed': 2**7,\\\n",
    "               'num_leaves': np.int(parameters[3]),\\\n",
    "               'bagging_freq':1,\\\n",
    "               'verbose': 0,\\\n",
    "               'max_bin': 2**14\\\n",
    "              }\n",
    "    \n",
    "    #hard code\n",
    "    n_estim = 500\n",
    "    early_stopping_rounds = 3\n",
    "    \n",
    "    gbr = lgbm.train(lgbm_params, \\\n",
    "    lgbm.Dataset(net_CSV.loc[tr_val_log_dict['training_logical'],cols], \\\n",
    "    label = net_CSV.loc[tr_val_log_dict['training_logical'],'deal_probability']), n_estim,\\\n",
    "    valid_sets = [lgbm.Dataset(net_CSV.loc[tr_val_log_dict['validation_logical'],cols], \n",
    "    label = net_CSV.loc[tr_val_log_dict['validation_logical'],'deal_probability'])],\\\n",
    "    early_stopping_rounds = early_stopping_rounds,verbose_eval = False)\n",
    "    \n",
    "    gbr_pred_val = gbr.predict(net_CSV.loc[tr_val_log_dict['validation_logical'],cols]).astype(np.float16)\n",
    "\n",
    "    rmse_val = \\\n",
    "    np.sqrt(((net_CSV.loc[tr_val_log_dict['validation_logical'],'deal_probability'] - \\\n",
    "    gbr_pred_val)**2).mean())\n",
    "    \n",
    "    score = np.array(rmse_val)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([6.58021333e-01, 5.99626521e-01, 8.96465506e-03, 4.09600000e+03,\n",
       "       2.00000000e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Bounds (NOTE: define continuous variables first, then discrete!)\n",
    "bounds_LGBM = [\n",
    "            {'name': 'feature_fraction', 'type': 'continuous', 'domain': (0.3, 0.7)},\\\n",
    "            {'name': 'bagging_fraction', 'type': 'continuous', 'domain': (0.1, 0.6)},\\\n",
    "            {'name': 'learning_rate', 'type': 'continuous', 'domain': (1E-5, 1E-2)},\\\n",
    "            {'name': 'num_leaves', 'type': 'discrete', 'domain': (2**3, 2**12)},\\\n",
    "            {'name': 'min_data_in_leaf', 'type': 'discrete', 'domain': (2, 2**15)}\\\n",
    "            ]\n",
    "\n",
    "#{'name': 'n_estim', 'type': 'discrete', 'domain': (50, 1E4)}\\\n",
    "\n",
    "np.random.seed(777)\n",
    "optimizer_LGBM = GPyOpt.methods.BayesianOptimization(f=f_LGBM, domain=bounds_LGBM,\\\n",
    "acquisition_type ='MPI',\\\n",
    "acquisition_par = 0.1,\\\n",
    "exact_eval=True)\n",
    "\n",
    "max_iter = 50\n",
    "#max_time = 500\n",
    "optimizer_LGBM.run_optimization(max_iter)\n",
    "\n",
    "optimizer_LGBM.plot_convergence()\n",
    "\n",
    "optimizer_LGBM.X[np.argmin(optimizer_LGBM.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22305141484438848\n"
     ]
    }
   ],
   "source": [
    "val_rmse = f_LGBM(np.array([6.58021333e-01, 5.99626521e-01, 8.96465506e-03, 2.00000000e+03,1.00000000e+02]),\\\n",
    "one_set_params_flag = True)\n",
    "\n",
    "print(val_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NIMA fieldnames to database...\n",
      "Done.\n",
      "Starting computation of NIMA metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8147ac5bd61d41e5af79bfd2e53a7ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=508438), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericz\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elapsed  = 240756.2 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#compute NIMA scores and add to database\n",
    "\n",
    "#does not need to be redone\n",
    "if False:\n",
    "    zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\train_jpg.zip\"\n",
    "    zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "    print(\"created zip object\")\n",
    "    \n",
    "    \n",
    "if False:\n",
    "    zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\test_jpg.zip\"\n",
    "    zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "    print(\"created zip object\")\n",
    "    #remember to close!\n",
    "    #zip_obj.close()\n",
    "    \n",
    "if False:\n",
    "    NIMA_model = load_NIMA()\n",
    "    print(\"loaded NIMA\")\n",
    "\n",
    "\n",
    "add_NIMA_score_to_database(net_CSV,train_CSV_flag = True, \\\n",
    "zip_obj = zip_obj,NIMA_model = NIMA_model,batch_size = 10,\\\n",
    "break_at = np.inf,\\\n",
    "save_interval = np.int(1E4),\\\n",
    "idx_start = 1503424,idx_end_exclusive = None)\n",
    "\n",
    "if False:\n",
    "    if True:\n",
    "        amin = train_CSV.loc[:99,'NIMA_mean'].argmin()\n",
    "        jpg_id = train_CSV.loc[amin,'image']\n",
    "    else:\n",
    "        amax = train_CSV.loc[:99,'NIMA_mean'].argmax()\n",
    "        jpg_id = train_CSV.loc[amax,'image']\n",
    "    \n",
    "    extract_jpg_from_zipfileobject(zip_obj,jpg_id,verbose = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "385646592/574710816 [===================>..........] - ETA: 1:42:3 - ETA: 1:09:1 - ETA: 1:02:2 - ETA: 47:01  - ETA: 40:4 - ETA: 37:3 - ETA: 33:4 - ETA: 30:1 - ETA: 25:4 - ETA: 23:3 - ETA: 20:1 - ETA: 17:5 - ETA: 16:0 - ETA: 14:0 - ETA: 12:2 - ETA: 10:3 - ETA: 10:3 - ETA: 9:1 - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21s574717952/574710816 [==============================] - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 76s 0us/step\n",
      "loaded object_classification_model\n",
      "Starting computation of object classification vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2194b9b37f45aaa1ac127f5433d183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1503424), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed  = 700388.7 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#compute onject classification vectors and save them as individual PKL files\n",
    "\n",
    "#does not need to be redone\n",
    "if False:\n",
    "    zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\train_jpg.zip\"\n",
    "    zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "    print(\"created zip object\")\n",
    "    train_CSV_flag = True\n",
    "    \n",
    "    \n",
    "if False:\n",
    "    zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\test_jpg.zip\"\n",
    "    zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "    print(\"created zip object\")\n",
    "    train_CSV_flag = False\n",
    "    #remember to close!\n",
    "    #zip_obj.close()\n",
    "    \n",
    "if True:\n",
    "    #object_classification_model = load_InceptionResNetV2()\n",
    "    object_classification_model = load_VGG19()\n",
    "    print(\"loaded object_classification_model\")\n",
    "\n",
    "\n",
    "    \n",
    "#InceptionResNetV2\n",
    "#target_size = (299,299)\n",
    "\n",
    "#VGG19\n",
    "target_size = (224,224)\n",
    "    \n",
    "save_object_classification_vectors(net_CSV, tr_val_log_dict,\\\n",
    "target_size = target_size, train_CSV_flag = train_CSV_flag,\\\n",
    "zip_obj = zip_obj,object_classification_model = object_classification_model,\\\n",
    "batch_size = 10,break_at = np.inf,\\\n",
    "idx_start = 0,idx_end_exclusive = None)\n",
    "\n",
    "#extract_jpg_from_zipfileobject(zip_obj,jpg_id,verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del object_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    zip_filename = r\"C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\train_jpg.zip\"\n",
    "    zip_obj = zipfile.ZipFile(zip_filename,mode = 'r') \n",
    "else:\n",
    "    zip_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n03388549', 'four-poster', 0.24008057),\n",
       "  ('n04344873', 'studio_couch', 0.2296804),\n",
       "  ('n04239074', 'sliding_door', 0.09342557),\n",
       "  ('n03788365', 'mosquito_net', 0.09014095),\n",
       "  ('n04590129', 'window_shade', 0.05248477)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg_id_list = \\\n",
    "[\"1262fadc0dc195fb021235cade2b37e09134b3d6a5012028d9047335afadfc94\"]\n",
    "\n",
    "object_classification_vector_list = load_object_classification_vectors(jpg_id_list)\n",
    "\n",
    "#extract_jpg_from_zipfileobject(zip_obj,jpg_id_list[0],verbose = False)\n",
    "\n",
    "decode_predictions(object_classification_vector_list[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d791934b3bed449fa7de83b74a3b3f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericz\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "categorical_vars_to_encode = ['param_1','param_2','param_3']\n",
    "\n",
    "add_1way_meanencodings(net_CSV,categorical_vars_to_encode,\\\n",
    "tr_val_log_dict,mean_fill_flag = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#add day of week field to database\n",
    "\n",
    "if 0:\n",
    "    add_day_of_week_field(train_CSV)\n",
    "else:\n",
    "    add_day_of_week_field(test_CSV)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save databases to CSV\n",
    "net_CSV.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_net.csv',index = False)\n",
    "#test_CSV.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_test.csv')\n",
    "#train_CSV.to_csv(r'C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_CSV.drop(labels = ['ME_param_1','ME_param_2','ME_param_3'],axis = 1,inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# (%) nulls for column NIMA_mean = 155201 (7.71%); # unique values = 1847579\n",
      "\n",
      "# (%) nulls for column NIMA_sd = 155201 (7.71%); # unique values = 1847754\n",
      "\n",
      "# (%) nulls for column activation_date = 0 (0.00%); # unique values = 30\n",
      "\n",
      "# (%) nulls for column category_name = 0 (0.00%); # unique values = 47\n",
      "\n",
      "# (%) nulls for column city = 0 (0.00%); # unique values = 1752\n",
      "\n",
      "# (%) nulls for column day_of_week = 0 (0.00%); # unique values = 7\n",
      "\n",
      "# (%) nulls for column deal_probability = 508438 (25.27%); # unique values = 18408\n",
      "\n",
      "# (%) nulls for column description = 116276 (5.78%); # unique values = 1794802\n",
      "\n",
      "# (%) nulls for column description_processed = 116578 (5.79%); # unique values = 1784344\n",
      "\n",
      "# (%) nulls for column description_processed_length = 508438 (25.27%); # unique values = 928\n",
      "\n",
      "# (%) nulls for column image = 155197 (7.71%); # unique values = 1856666\n",
      "\n",
      "# (%) nulls for column image_top_1 = 155197 (7.71%); # unique values = 3064\n",
      "\n",
      "# (%) nulls for column item_id = 0 (0.00%); # unique values = 2011862\n",
      "\n",
      "# (%) nulls for column item_seq_number = 0 (0.00%); # unique values = 33947\n",
      "\n",
      "# (%) nulls for column param_1 = 84486 (4.20%); # unique values = 372\n",
      "\n",
      "# (%) nulls for column param_2 = 887771 (44.13%); # unique values = 278\n",
      "\n",
      "# (%) nulls for column param_3 = 1168896 (58.10%); # unique values = 1277\n",
      "\n",
      "# (%) nulls for column parent_category_name = 0 (0.00%); # unique values = 9\n",
      "\n",
      "# (%) nulls for column price = 115947 (5.76%); # unique values = 20755\n",
      "\n",
      "# (%) nulls for column region = 0 (0.00%); # unique values = 28\n",
      "\n",
      "# (%) nulls for column source = 0 (0.00%); # unique values = 2\n",
      "\n",
      "# (%) nulls for column title = 0 (0.00%); # unique values = 1022203\n",
      "\n",
      "# (%) nulls for column title_processed = 3 (0.00%); # unique values = 992863\n",
      "\n",
      "# (%) nulls for column tokenized_category_name = 0 (0.00%); # unique values = 47\n",
      "\n",
      "# (%) nulls for column tokenized_param_1 = 0 (0.00%); # unique values = 372\n",
      "\n",
      "# (%) nulls for column tokenized_param_2 = 0 (0.00%); # unique values = 271\n",
      "\n",
      "# (%) nulls for column tokenized_param_3 = 0 (0.00%); # unique values = 1190\n",
      "\n",
      "# (%) nulls for column tokenized_parent_category_name = 0 (0.00%); # unique values = 9\n",
      "\n",
      "# (%) nulls for column tokenized_user_type = 0 (0.00%); # unique values = 3\n",
      "\n",
      "# (%) nulls for column user_id = 0 (0.00%); # unique values = 1009909\n",
      "\n",
      "# (%) nulls for column user_type = 0 (0.00%); # unique values = 3\n",
      "\n",
      "# (%) nulls for column ME_region = 0 (0.00%); # unique values = 168\n",
      "\n",
      "# (%) nulls for column ME_city = 0 (0.00%); # unique values = 8432\n",
      "\n",
      "# (%) nulls for column ME_parent_category_name = 0 (0.00%); # unique values = 54\n",
      "\n",
      "# (%) nulls for column ME_item_seq_number = 0 (0.00%); # unique values = 23081\n",
      "\n",
      "# (%) nulls for column ME_user_type = 0 (0.00%); # unique values = 18\n",
      "\n",
      "# (%) nulls for column ME_category_name = 0 (0.00%); # unique values = 282\n",
      "\n",
      "# (%) nulls for column ME_day_of_week = 0 (0.00%); # unique values = 42\n",
      "\n",
      "# (%) nulls for column ME_param_1 = 84496 (4.20%); # unique values = 2090\n",
      "\n",
      "# (%) nulls for column ME_param_2 = 887801 (44.13%); # unique values = 1403\n",
      "\n",
      "# (%) nulls for column ME_param_3 = 1169294 (58.12%); # unique values = 4265\n"
     ]
    }
   ],
   "source": [
    "report_na(net_CSV,verbose_columns = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(2011862, 36)\n",
      "Товары для детей и игрушки\n",
      "Личные вещи\n"
     ]
    }
   ],
   "source": [
    "print(net_CSV['user_type'].unique().shape)\n",
    "print(net_CSV.shape)\n",
    "print(net_CSV.loc[0,'category_name'])\n",
    "print(net_CSV.loc[0,'parent_category_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:\\Users\\ericz\\Documents\\AvitoCompetition\\data\\processed_net.csv...\n"
     ]
    }
   ],
   "source": [
    "train_active_csv = load_active_CSV(os.path.join(AVITO_DATA_DIR,'train_active.csv'),nrows = 10,skiprows = 0)\n",
    "net_CSV = load_main_CSV(os.path.join(AVITO_DATA_DIR,'processed_net.csv'),nrows = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now pre-processing fieldname: title\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6555c4aa5b42bbbcb0e6184780b602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=508438), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericz\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "% of tokens in embedding = 90.53\n",
      "time elapsed = 1005.7 s\n"
     ]
    }
   ],
   "source": [
    "preprocess_fields_for_tokenizing(test_CSV,fieldnames_to_preprocess = ['description','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_columns(database1,database2):\n",
    "    \"\"\"\n",
    "    Creates dataframe which indicates whether the union of the fieldnames of the\n",
    "    competition train and test CSVs are present in each.\n",
    "    \"\"\"\n",
    "    \n",
    "    database1_columns = list(database1.columns.values)\n",
    "    database2_columns = list(database2.columns.values)\n",
    "    \n",
    "    net_columns = list(set(database1_columns).union(set(database2_columns)))\n",
    "    \n",
    "    num_net_columns = len(net_columns)\n",
    "    \n",
    "    columns_present_db = pd.DataFrame({'column_name': num_net_columns*[None],\\\n",
    "    'in_database1':num_net_columns*[None],\\\n",
    "    'in_database2':num_net_columns*[None]})\n",
    "    \n",
    "    for idx,col in enumerate(net_columns):\n",
    "        \n",
    "        columns_present_db.loc[idx,'column_name'] = col\n",
    "        columns_present_db.loc[idx,'in_database1'] = col in database1_columns\n",
    "        columns_present_db.loc[idx,'in_database2'] = col in database2_columns\n",
    "        \n",
    "    return columns_present_db\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       column_name in_database1 in_database2\n",
      "0                tokenized_param_3         True        False\n",
      "1                           region         True         True\n",
      "2                        NIMA_mean         True        False\n",
      "3                       ME_param_2         True        False\n",
      "4                   ME_day_of_week         True        False\n",
      "5                      image_top_1         True        False\n",
      "6     description_processed_length         True        False\n",
      "7                  title_processed         True        False\n",
      "8                          param_2         True         True\n",
      "9                          item_id         True         True\n",
      "10               tokenized_param_1         True        False\n",
      "11              ME_item_seq_number         True        False\n",
      "12                    ME_user_type         True        False\n",
      "13                         param_3         True         True\n",
      "14                           price         True         True\n",
      "15  tokenized_parent_category_name         True        False\n",
      "16                     description         True         True\n",
      "17                   category_name         True         True\n",
      "18                     day_of_week         True        False\n",
      "19         tokenized_category_name         True        False\n",
      "20         ME_parent_category_name         True        False\n",
      "21                       user_type         True         True\n",
      "22                      ME_param_1         True        False\n",
      "23               tokenized_param_2         True        False\n",
      "24                 item_seq_number         True         True\n",
      "25                ME_category_name         True        False\n",
      "26                          source         True        False\n",
      "27                         ME_city         True        False\n",
      "28                deal_probability         True        False\n",
      "29                       ME_region         True        False\n",
      "30                           image         True        False\n",
      "31                           title         True         True\n",
      "32                 activation_date         True         True\n",
      "33                      ME_param_3         True        False\n",
      "34                         param_1         True         True\n",
      "35                         user_id         True         True\n",
      "36                         NIMA_sd         True        False\n",
      "37             tokenized_user_type         True        False\n",
      "38                            city         True         True\n",
      "39            parent_category_name         True         True\n",
      "40           description_processed         True        False\n"
     ]
    }
   ],
   "source": [
    "columns_present_db = compare_columns(net_CSV,train_active_csv)\n",
    "print(columns_present_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_CSV = pd.concat([train_CSV,test_CSV],ignore_index = True,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train_CSV\n",
    "    print(\"deleted train_CSV\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del test_CSV\n",
    "    print(\"deleted test_CSV\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator= Translator(to_lang=\"en\",from_lang = \"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.translate('Волгоградская область')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n'\n",
    "print(translator.translate(text))\n",
    "'in dict' if word_to_glove_vec.get(text) is not None else \"not in dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
